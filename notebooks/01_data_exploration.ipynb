{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë°ì´í„° íƒìƒ‰ ë° DB ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ê°€ê²© ì˜ˆì¸¡ í”„ë¡œì íŠ¸ì˜ ë°ì´í„° íƒìƒ‰ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.db_connector import DatabaseConnector, SessionManager\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "print(\"=\" * 50)\n",
    "print(\"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    with DatabaseConnector() as db:\n",
    "        print(\"âœ“ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!\\n\")\n",
    "        \n",
    "        # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ\n",
    "        tables = db.get_table_list()\n",
    "        print(f\"âœ“ ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ìˆ˜: {len(tables)}\")\n",
    "        print(\"\\ní…Œì´ë¸” ëª©ë¡:\")\n",
    "        for i, table in enumerate(tables[:10], 1):\n",
    "            print(f\"  {i}. {table}\")\n",
    "        \n",
    "        if len(tables) > 10:\n",
    "            print(f\"  ... ì™¸ {len(tables) - 10}ê°œ\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âœ— ì—°ê²° ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step 1: ì¢…ëª© í•„í„°ë§ (ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ ìƒì„±)\n",
    "\n",
    "ëª©í‘œ: NYSE, NASDAQ, AMEX ì¢…ëª© ì¤‘ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª© ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORM ëª¨ë¸ ì„í¬íŠ¸\n",
    "from src.data.models import (\n",
    "    DS2CtryQtInfo, \n",
    "    DS2Exchange, \n",
    "    DS2PrimQtPrc,\n",
    "    VwDs2Pricing,\n",
    "    VwDs2MktCap,\n",
    "    RKDFndInfo  # Ticker, ISIN ì •ë³´ë¥¼ ìœ„í•´ ì¶”ê°€\n",
    ")\n",
    "from sqlalchemy import func, and_, or_\n",
    "from sqlalchemy.orm import aliased\n",
    "\n",
    "print(\"âœ“ ORM ëª¨ë¸ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: NYSE, NASDAQ, AMEX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (ORM ì‚¬ìš© + Ticker/ISIN + ê±°ë˜ì†Œëª…)\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 1: ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (ORM) with Ticker/ISIN/Exchange\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    with DatabaseConnector() as db:\n",
    "        with SessionManager(db) as session:\n",
    "            # 1. NYSE, NASDAQ, AMEX ê±°ë˜ì†Œ í•„í„°ë§\n",
    "            print(\"\\n[1] NYSE, NASDAQ, AMEX í•„í„°ë§...\")\n",
    "            target_exchanges = session.query(DS2Exchange).filter(\n",
    "                and_(\n",
    "                    DS2Exchange.ExchCtryCode == 'US',\n",
    "                    or_(\n",
    "                        DS2Exchange.ExchName.like('%NYSE%'),\n",
    "                        DS2Exchange.ExchName.like('%NASDAQ%'),\n",
    "                        DS2Exchange.ExchName.like('%AMEX%')\n",
    "                    )\n",
    "                )\n",
    "            ).all()\n",
    "            \n",
    "            print(f\"âœ“ ëŒ€ìƒ ê±°ë˜ì†Œ:\")\n",
    "            for exch in target_exchanges[:5]:\n",
    "                print(f\"  - {exch.ExchName} (ì½”ë“œ: {exch.ExchIntCode})\")\n",
    "            if len(target_exchanges) > 5:\n",
    "                print(f\"  ... ì™¸ {len(target_exchanges) - 5}ê°œ\")\n",
    "            \n",
    "            target_exch_codes = [exch.ExchIntCode for exch in target_exchanges]\n",
    "            \n",
    "            # 2. ì¢…ëª© ì¡°íšŒ (ê±°ë˜ì†Œ, Ticker/ISIN ì •ë³´ í¬í•¨)\n",
    "            print(f\"\\n[2] ì¢…ëª© ì¡°íšŒ ì¤‘...\")\n",
    "            \n",
    "            # DS2PrimQtPrcì—ì„œ ê±°ë˜ì†Œë³„ ì¢…ëª© ì¡°íšŒ í›„ DS2Exchange ì¡°ì¸\n",
    "            stocks = session.query(\n",
    "                DS2CtryQtInfo.InfoCode,\n",
    "                DS2CtryQtInfo.DsCode,\n",
    "                DS2CtryQtInfo.DsQtName,\n",
    "                DS2CtryQtInfo.StatusCode,\n",
    "                DS2CtryQtInfo.DelistDate,\n",
    "                DS2PrimQtPrc.ExchIntCode,\n",
    "                DS2Exchange.ExchName,\n",
    "                DS2Exchange.ExchMnem,\n",
    "                RKDFndInfo.Ticker,\n",
    "                RKDFndInfo.ISIN,\n",
    "                RKDFndInfo.Cusip,\n",
    "                RKDFndInfo.Sedol,\n",
    "            ).join(\n",
    "                DS2PrimQtPrc,\n",
    "                DS2CtryQtInfo.InfoCode == DS2PrimQtPrc.InfoCode\n",
    "            ).join(\n",
    "                DS2Exchange,\n",
    "                DS2PrimQtPrc.ExchIntCode == DS2Exchange.ExchIntCode\n",
    "            ).outerjoin(\n",
    "                RKDFndInfo, \n",
    "                DS2CtryQtInfo.InfoCode == RKDFndInfo.Code\n",
    "            ).filter(\n",
    "                and_(\n",
    "                    DS2CtryQtInfo.Region == 'US',\n",
    "                    DS2CtryQtInfo.IsPrimQt == 1,\n",
    "                    DS2PrimQtPrc.ExchIntCode.in_(target_exch_codes)\n",
    "                )\n",
    "            ).distinct().limit(100).all()\n",
    "            \n",
    "            print(f\"âœ“ ì¡°íšŒëœ ì¢…ëª© ìˆ˜: {len(stocks)} (ìƒ˜í”Œ 100ê°œ)\")\n",
    "            \n",
    "            # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "            df_stocks = pd.DataFrame([\n",
    "                {\n",
    "                    'InfoCode': s.InfoCode,\n",
    "                    'DsCode': s.DsCode,\n",
    "                    'DsQtName': s.DsQtName,\n",
    "                    'Exchange': s.ExchName,\n",
    "                    'ExchMnem': s.ExchMnem,\n",
    "                    'ExchIntCode': s.ExchIntCode,\n",
    "                    'Ticker': s.Ticker,\n",
    "                    'ISIN': s.ISIN,\n",
    "                    'Cusip': s.Cusip,\n",
    "                    'Sedol': s.Sedol,\n",
    "                    'StatusCode': s.StatusCode,\n",
    "                    'DelistDate': s.DelistDate,\n",
    "                }\n",
    "                for s in stocks\n",
    "            ])\n",
    "            \n",
    "            print(f\"\\nâœ“ ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ:\")\n",
    "            print(f\"  - Shape: {df_stocks.shape}\")\n",
    "            print(f\"  - Ticker ë§¤í•‘ë¥ : {df_stocks['Ticker'].notna().sum()}/{len(df_stocks)} ({df_stocks['Ticker'].notna().sum()/len(df_stocks)*100:.1f}%)\")\n",
    "            print(f\"  - ISIN ë§¤í•‘ë¥ : {df_stocks['ISIN'].notna().sum()}/{len(df_stocks)} ({df_stocks['ISIN'].notna().sum()/len(df_stocks)*100:.1f}%)\")\n",
    "            print(f\"  - ìƒì¥íì§€ ì¢…ëª©: {df_stocks['DelistDate'].notna().sum()}\")\n",
    "            \n",
    "            print(f\"\\nâœ“ ê±°ë˜ì†Œë³„ ë¶„í¬:\")\n",
    "            print(df_stocks['Exchange'].value_counts())\n",
    "            \n",
    "            print(f\"\\nìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 10ê°œ):\")\n",
    "            print(df_stocks[['DsCode', 'DsQtName', 'Exchange', 'Ticker', 'ISIN']].head(10))\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âœ— ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    df_stocks = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.to_csv(\"df_stocks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step 2: ê°­ ìƒìŠ¹ ë°ì´í„° ì¶”ì¶œ\n",
    "\n",
    "ëª©í‘œ: ê±°ë˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ ì°¾ê¸°\n",
    "- ê°­ ìƒìŠ¹ë¥  = (ë‹¹ì¼ ì‹œê°€ - ì „ì¼ ì¢…ê°€) / ì „ì¼ ì¢…ê°€ Ã— 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2-1: ìƒ˜í”Œ ì¢…ëª©ì˜ ì¼ë³„ ê°€ê²© ë°ì´í„° ì¡°íšŒ ë° ê°­ ìƒìŠ¹ ê³„ì‚°\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 2: ê°­ ìƒìŠ¹ ë°ì´í„° ì¶”ì¶œ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not df_stocks.empty:\n",
    "    # ìƒ˜í”Œ ì¢…ëª© ì„ íƒ (ìƒì¥ ì¤‘ì¸ ì¢…ëª© ì¤‘ 5ê°œ)\n",
    "    sample_stocks = df_stocks[df_stocks['DelistDate'].isna()].head(5)\n",
    "    sample_info_codes = sample_stocks['InfoCode'].tolist()\n",
    "    \n",
    "    print(f\"\\nìƒ˜í”Œ ì¢…ëª© ({len(sample_info_codes)}ê°œ):\")\n",
    "    for _, stock in sample_stocks.iterrows():\n",
    "        print(f\"  - {stock['DsQtName']} ({stock['Ticker']}) / {stock['Exchange']}\")\n",
    "    \n",
    "    try:\n",
    "        with DatabaseConnector() as db:\n",
    "            with SessionManager(db) as session:\n",
    "                print(f\"\\nì¼ë³„ ê°€ê²© ë°ì´í„° ì¡°íšŒ ì¤‘...\")\n",
    "                \n",
    "                # ì¼ë³„ OHLCV ë°ì´í„° ì¡°íšŒ (ìµœê·¼ 2ë…„)\n",
    "                from datetime import datetime, timedelta\n",
    "                start_date = datetime.now() - timedelta(days=730)  # 2ë…„\n",
    "                \n",
    "                prices = session.query(\n",
    "                    DS2PrimQtPrc.InfoCode,\n",
    "                    DS2PrimQtPrc.MarketDate,\n",
    "                    DS2PrimQtPrc.Open_,\n",
    "                    DS2PrimQtPrc.High,\n",
    "                    DS2PrimQtPrc.Low,\n",
    "                    DS2PrimQtPrc.Close_,\n",
    "                    DS2PrimQtPrc.Volume,\n",
    "                ).filter(\n",
    "                    and_(\n",
    "                        DS2PrimQtPrc.InfoCode.in_(sample_info_codes),\n",
    "                        DS2PrimQtPrc.MarketDate >= start_date,\n",
    "                        DS2PrimQtPrc.Open_.isnot(None),\n",
    "                        DS2PrimQtPrc.Close_.isnot(None)\n",
    "                    )\n",
    "                ).order_by(\n",
    "                    DS2PrimQtPrc.InfoCode,\n",
    "                    DS2PrimQtPrc.MarketDate\n",
    "                ).all()\n",
    "                \n",
    "                print(f\"âœ“ ì¡°íšŒëœ ë ˆì½”ë“œ ìˆ˜: {len(prices):,}\")\n",
    "                \n",
    "                # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "                df_prices = pd.DataFrame([\n",
    "                    {\n",
    "                        'InfoCode': p.InfoCode,\n",
    "                        'MarketDate': p.MarketDate,\n",
    "                        'Open': p.Open_,\n",
    "                        'High': p.High,\n",
    "                        'Low': p.Low,\n",
    "                        'Close': p.Close_,\n",
    "                        'Volume': p.Volume,\n",
    "                    }\n",
    "                    for p in prices\n",
    "                ])\n",
    "                \n",
    "                # ì¢…ëª©ë³„ë¡œ ì „ì¼ ì¢…ê°€ ê³„ì‚° ë° ê°­ ê³„ì‚°\n",
    "                print(f\"\\nê°­ ìƒìŠ¹ ê³„ì‚° ì¤‘...\")\n",
    "                df_prices = df_prices.sort_values(['InfoCode', 'MarketDate'])\n",
    "                df_prices['PrevClose'] = df_prices.groupby('InfoCode')['Close'].shift(1)\n",
    "                df_prices['Gap_Pct'] = ((df_prices['Open'] - df_prices['PrevClose']) / df_prices['PrevClose'] * 100)\n",
    "                df_prices['Intraday_Return'] = ((df_prices['Close'] - df_prices['Open']) / df_prices['Open'] * 100)\n",
    "                \n",
    "                # ê°­ ìƒìŠ¹ í•„í„°ë§ (ê°­ > 0%)\n",
    "                df_gap_up = df_prices[df_prices['Gap_Pct'] > 0].copy()\n",
    "                df_gap_up['Target'] = (df_gap_up['Intraday_Return'] > 0).astype(int)\n",
    "                \n",
    "                print(f\"âœ“ ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ ìˆ˜: {len(df_gap_up):,}\")\n",
    "                print(f\"âœ“ ì „ì²´ ê±°ë˜ì¼ ëŒ€ë¹„ ë¹„ìœ¨: {len(df_gap_up)/len(df_prices)*100:.1f}%\")\n",
    "                \n",
    "                # ì¢…ëª© ì •ë³´ ë§¤í•‘\n",
    "                df_gap_up = df_gap_up.merge(\n",
    "                    df_stocks[['InfoCode', 'DsQtName', 'Ticker', 'Exchange']],\n",
    "                    on='InfoCode',\n",
    "                    how='left'\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nâœ“ ê°­ ìƒìŠ¹ í†µê³„:\")\n",
    "                print(f\"  - í‰ê·  ê°­ ìƒìŠ¹ë¥ : {df_gap_up['Gap_Pct'].mean():.2f}%\")\n",
    "                print(f\"  - ì¤‘ê°„ ê°­ ìƒìŠ¹ë¥ : {df_gap_up['Gap_Pct'].median():.2f}%\")\n",
    "                print(f\"  - ìµœëŒ€ ê°­ ìƒìŠ¹ë¥ : {df_gap_up['Gap_Pct'].max():.2f}%\")\n",
    "                print(f\"  - ë‹¹ì¼ ìƒìŠ¹ ë¹„ìœ¨ (Target=1): {df_gap_up['Target'].mean()*100:.1f}%\")\n",
    "                \n",
    "                print(f\"\\nìƒ˜í”Œ ê°­ ìƒìŠ¹ ë°ì´í„° (ìµœê·¼ 10ê°œ):\")\n",
    "                print(df_gap_up[['MarketDate', 'DsQtName', 'Ticker', 'Gap_Pct', 'Intraday_Return', 'Target']].tail(10))\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        df_gap_up = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\nâœ— ì¢…ëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    df_gap_up = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step 3: ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "**ëª©í‘œ:** \n",
    "- DataLoader, DataPreprocessor, Feature Engineering ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸\n",
    "- ì†Œìˆ˜ ì¢…ëª©ìœ¼ë¡œ ë¹ ë¥´ê²Œ ê²€ì¦ í›„ ì „ì²´ ì¢…ëª© ì ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. ëª¨ë“ˆ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.preprocessor import DataPreprocessor\n",
    "from src.features import add_technical_features_parallel, add_market_context\n",
    "\n",
    "print(\"âœ“ ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. ë°ì´í„° ë¡œë” ì´ˆê¸°í™” ë° ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "**í…ŒìŠ¤íŠ¸ ì „ëµ:**\n",
    "- ë¨¼ì € 10ê°œ ì¢…ëª©ìœ¼ë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸\n",
    "- ë¬¸ì œ ì—†ìœ¼ë©´ ì „ì²´ ì¢…ëª©ìœ¼ë¡œ í™•ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: DataLoader ì´ˆê¸°í™”\n",
    "print(\"=\"*80)\n",
    "print(\"Step 1: DataLoader ì´ˆê¸°í™”\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "loader = DataLoader(config_path=\"../config/config.yaml\")\n",
    "print(f\"âœ“ Config loaded: {loader.config.get('data', {}).get('min_years', 10)} years\")\n",
    "print(f\"âœ“ Batch size: {loader.config.get('data', {}).get('parallel', {}).get('batch_size', 100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: ìƒ˜í”Œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (10ê°œ)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 2: ìƒ˜í”Œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ\n",
    "stock_list_full = loader.get_stock_list()\n",
    "print(f\"âœ“ ì „ì²´ ì¢…ëª© ìˆ˜: {len(stock_list_full)}\")\n",
    "\n",
    "# ìƒ˜í”Œ 10ê°œ ì„ íƒ (ìƒì¥ ì¤‘ì¸ ì¢…ëª© ìš°ì„ )\n",
    "sample_stocks = stock_list_full[stock_list_full['DelistDate'].isna()].head(10)\n",
    "print(f\"âœ“ ìƒ˜í”Œ ì¢…ëª© ìˆ˜: {len(sample_stocks)}\")\n",
    "\n",
    "print(\"\\nìƒ˜í”Œ ì¢…ëª© ëª©ë¡:\")\n",
    "for idx, row in sample_stocks.iterrows():\n",
    "    print(f\"  {row['InfoCode']}: {row['DsQtName']} ({row['Ticker']}) - {row['Exchange']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ì„¹í„°/ì‚°ì—… ì •ë³´ ë¡œë“œ\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 3: ì„¹í„°/ì‚°ì—… ì •ë³´ ë¡œë“œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_info_codes = sample_stocks['InfoCode'].tolist()\n",
    "sector_info = loader.load_sector_industry(sample_info_codes)\n",
    "\n",
    "# ìƒ˜í”Œ ì¢…ëª©ê³¼ ë³‘í•©\n",
    "sample_stocks_with_sector = sample_stocks.merge(sector_info, on='InfoCode', how='left')\n",
    "\n",
    "print(f\"âœ“ ì„¹í„° ì •ë³´ ì¡°íšŒ ì™„ë£Œ\")\n",
    "print(f\"  - ì„¹í„° ë§¤í•‘ë¥ : {sample_stocks_with_sector['sector'].notna().sum()}/{len(sample_stocks_with_sector)}\")\n",
    "print(f\"  - ì‚°ì—… ë§¤í•‘ë¥ : {sample_stocks_with_sector['industry'].notna().sum()}/{len(sample_stocks_with_sector)}\")\n",
    "\n",
    "print(\"\\nì„¹í„°/ì‚°ì—… ì •ë³´:\")\n",
    "print(sample_stocks_with_sector[['DsQtName', 'sector', 'industry']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: OHLCV ë°ì´í„° ë¡œë“œ (ìµœê·¼ 2ë…„)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 4: OHLCV ë°ì´í„° ë¡œë“œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime.now() - timedelta(days=365 * 2)  # 2ë…„\n",
    "print(f\"ê¸°ê°„: {start_date.date()} ~ {datetime.now().date()}\")\n",
    "\n",
    "# ë³‘ë ¬ë¡œ OHLCV ë¡œë“œ (ìˆ˜ì •: DataFrame ì „ë‹¬)\n",
    "ohlcv_sample = loader.load_ohlcv_batch(sample_stocks_with_sector, start_date, adj_type=2)\n",
    "\n",
    "print(f\"\\nâœ“ OHLCV ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"  - ì´ ë ˆì½”ë“œ ìˆ˜: {len(ohlcv_sample):,}\")\n",
    "print(f\"  - ì¢…ëª© ìˆ˜: {ohlcv_sample['InfoCode'].nunique()}\")\n",
    "print(f\"  - ë‚ ì§œ ë²”ìœ„: {ohlcv_sample['date'].min()} ~ {ohlcv_sample['date'].max()}\")\n",
    "\n",
    "print(\"\\nìƒ˜í”Œ ë°ì´í„°:\")\n",
    "print(ohlcv_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ (SPY, QQQ, VIX)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 5: ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "market_indices = loader.load_market_indices(start_date)\n",
    "\n",
    "if not market_indices.empty:\n",
    "    print(f\"âœ“ ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(f\"  - ë ˆì½”ë“œ ìˆ˜: {len(market_indices):,}\")\n",
    "    print(f\"  - ì»¬ëŸ¼: {list(market_indices.columns)}\")\n",
    "    print(\"\\nìƒ˜í”Œ ë°ì´í„°:\")\n",
    "    print(market_indices.head())\n",
    "else:\n",
    "    print(\"âœ— ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3. ë°ì´í„° ì „ì²˜ë¦¬ (Preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: ë°ì´í„° ì „ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 6: ë°ì´í„° ì „ì²˜ë¦¬\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Preprocessor ì´ˆê¸°í™”\n",
    "preprocessor = DataPreprocessor(loader.config)\n",
    "\n",
    "# preprocessed_df ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš©)\n",
    "df_preprocessed = preprocessor.create_preprocessed_df(\n",
    "    ohlcv_df=ohlcv_sample,\n",
    "    stock_list=sample_stocks_with_sector,\n",
    "    market_cap_df=None,  # ì‹œê°€ì´ì•¡ì€ ìƒëµ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "    use_parallel=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ ì „ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"  - ìµœì¢… Shape: {df_preprocessed.shape}\")\n",
    "print(f\"  - ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸: {df_preprocessed['is_gap_up'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-4. Feature Engineering (ê¸°ìˆ ì  ì§€í‘œ + ì‹œì¥ ì»¨í…ìŠ¤íŠ¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ (ë³‘ë ¬ ì²˜ë¦¬)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 7: ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_with_technical = add_technical_features_parallel(df_preprocessed, max_workers=4)\n",
    "\n",
    "print(f\"\\nâœ“ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ ì™„ë£Œ\")\n",
    "print(f\"  - Shape: {df_with_technical.shape}\")\n",
    "\n",
    "# ì¶”ê°€ëœ ì»¬ëŸ¼ í™•ì¸\n",
    "technical_cols = ['ma_5', 'ma_20', 'ma_50', 'rsi_14', 'atr_14', 'bollinger_position']\n",
    "print(f\"\\nê¸°ìˆ ì  ì§€í‘œ ìƒ˜í”Œ:\")\n",
    "print(df_with_technical[['date', 'DsQtName', 'close'] + technical_cols].tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 8: ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_final = add_market_context(df_with_technical, market_indices)\n",
    "\n",
    "print(f\"\\nâœ“ ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ ì™„ë£Œ\")\n",
    "print(f\"  - ìµœì¢… Shape: {df_final.shape}\")\n",
    "\n",
    "# ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í™•ì¸\n",
    "market_cols = ['spy_gap_pct', 'qqq_gap_pct', 'market_gap_diff', 'vix_level', \n",
    "               'sector', 'sector_gap_pct', 'sector_relative_gap']\n",
    "print(f\"\\nì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\")\n",
    "print(df_final[['date', 'DsQtName', 'gap_pct'] + market_cols].tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-5. ìµœì¢… ê²°ê³¼ í™•ì¸ ë° í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ê²°ê³¼ í™•ì¸\n",
    "print(\"=\"*80)\n",
    "print(\"ìµœì¢… ë°ì´í„°í”„ë ˆì„ ì •ë³´\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. ê¸°ë³¸ ì •ë³´\")\n",
    "print(f\"   - Shape: {df_final.shape}\")\n",
    "print(f\"   - ì¢…ëª© ìˆ˜: {df_final['InfoCode'].nunique()}\")\n",
    "print(f\"   - ë‚ ì§œ ë²”ìœ„: {df_final['date'].min()} ~ {df_final['date'].max()}\")\n",
    "print(f\"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df_final.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(f\"\\n2. ì»¬ëŸ¼ êµ¬ì„± ({len(df_final.columns)}ê°œ)\")\n",
    "print(f\"   - ì „ì²´ ì»¬ëŸ¼: {list(df_final.columns[:20])}...\")\n",
    "\n",
    "print(f\"\\n3. ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ í†µê³„\")\n",
    "gap_up_df = df_final[df_final['is_gap_up'] == 1]\n",
    "print(f\"   - ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ ìˆ˜: {len(gap_up_df):,}\")\n",
    "print(f\"   - í‰ê·  ê°­ ìƒìŠ¹ë¥ : {gap_up_df['gap_pct'].mean():.2f}%\")\n",
    "print(f\"   - ë‹¹ì¼ ìƒìŠ¹ ë¹„ìœ¨: {gap_up_df['target_direction'].mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n4. Feature ì»¤ë²„ë¦¬ì§€\")\n",
    "print(f\"   - ì„¹í„° ì •ë³´: {df_final['sector'].notna().sum()}/{len(df_final)} ({df_final['sector'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"   - ì‚°ì—… ì •ë³´: {df_final['industry'].notna().sum()}/{len(df_final)} ({df_final['industry'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"   - RSI 14: {df_final['rsi_14'].notna().sum()}/{len(df_final)} ({df_final['rsi_14'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"   - SPY ê°­: {df_final['spy_gap_pct'].notna().sum()}/{len(df_final)} ({df_final['spy_gap_pct'].notna().mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n5. ìƒ˜í”Œ ë°ì´í„° (ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ë§Œ)\")\n",
    "display_cols = ['date', 'DsQtName', 'sector', 'gap_pct', 'target_direction', \n",
    "                'rsi_14', 'spy_gap_pct', 'market_gap_diff']\n",
    "print(gap_up_df[display_cols].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"korea.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-6. ë°ì´í„° ì €ì¥ (ì„ íƒì )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„° ì €ì¥ (ì„ íƒì )\n",
    "# ì£¼ì„ ì œê±°í•˜ì—¬ ì‹¤í–‰\n",
    "\n",
    "save_path = \"../data/processed/sample_preprocessed_df.parquet\"\n",
    "preprocessor.save_to_file(df_final, save_path)\n",
    "print(f\"âœ“ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "\n",
    "print(\"ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë¬¸ì œ ì—†ìœ¼ë©´ ì „ì²´ ì¢…ëª©ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ìµœì¢… ë°ì´í„° ì¶”ì¶œ (5-1 ~ 5-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.preprocessor import DataPreprocessor\n",
    "\n",
    "print(\"âœ“ ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\")\n",
    "\n",
    "# Step 1: ì´ˆê¸°í™”\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 1: ì´ˆê¸°í™”\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "loader = DataLoader(config_path=\"../config/config.yaml\")\n",
    "preprocessor = DataPreprocessor(loader.config)\n",
    "print(\"âœ“ DataLoader ë° Preprocessor ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# Step 2: ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 2: ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stock_list_full = loader.get_stock_list()\n",
    "print(f\"âœ“ ì „ì²´ ì¢…ëª© ìˆ˜: {len(stock_list_full):,}\")\n",
    "\n",
    "# Step 3: ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ (ê³µí†µ)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 3: ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_date = datetime.now() - timedelta(days=365 * 20)  # 20ë…„\n",
    "market_indices = loader.load_market_indices(start_date)\n",
    "\n",
    "print(f\"âœ“ ì‹œì¥ ì§€ìˆ˜ ë°ì´í„°: {len(market_indices):,} ë ˆì½”ë“œ\")\n",
    "print(f\"âœ“ ë‚ ì§œ ë²”ìœ„: {market_indices['date'].min()} ~ {market_indices['date'].max()}\")\n",
    "\n",
    "# Step 4: ì¢…ëª©ë³„ ì ì§„ì  ì²˜ë¦¬ (í•µì‹¬!)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 4: ì¢…ëª©ë³„ ì ì§„ì  ì²˜ë¦¬\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_final = preprocessor.process_stocks_incrementally(\n",
    "    stock_list=stock_list_full,\n",
    "    data_loader=loader,\n",
    "    market_indices=market_indices,\n",
    "    start_date=start_date,\n",
    "    batch_size=100,  # í•œ ë²ˆì— 100ê°œ ì¢…ëª©ì”©\n",
    "    save_batch_files=True,\n",
    "    batch_output_dir=\"../data/processed/batches\",\n",
    "    final_output=\"../data/processed\",\n",
    "    apply_outlier_fix=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"ìµœì¢… ë°ì´í„° Shape: {df_final.shape}\")\n",
    "print(f\"ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸: {df_final['is_gap_up'].sum():,}\")\n",
    "print(f\"íŒŒì¼ ì €ì¥ ìœ„ì¹˜: ../data/processed/preprocessed_df_full.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#ì—¬ê¸°ì½”ë“œë¡œ ì‘ì„± \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_fianl = \u001b[43mpd\u001b[49m.read_parquet(\u001b[33m\"\u001b[39m\u001b[33m../data/processed/preprocessed_df_full.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## ì´ìƒì¹˜ ì œê±° \u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#ì—¬ê¸°ì½”ë“œë¡œ ì‘ì„± \n",
    "\n",
    "df_final = pd.read_parquet(\"../data/processed/preprocessed_df_full.parquet\")\n",
    "## ì´ìƒì¹˜ ì œê±° \n",
    "df_final.to_parquet(\"../data/processed/preprocessed_df_full_outlier_fix.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ê²ƒ\n",
    "1. **ë°ì´í„° ë¡œë”** - ì¢…ëª© ë¦¬ìŠ¤íŠ¸, OHLCV, ì„¹í„°/ì‚°ì—…, ì‹œì¥ ì§€ìˆ˜ ë¡œë“œ\n",
    "2. **ì „ì²˜ë¦¬** - ê°­ ê³„ì‚°, ìˆ˜ìµë¥ , ê±°ë˜ëŸ‰, ì‹œê°„ Features (ë³‘ë ¬ ì²˜ë¦¬)\n",
    "3. **ê¸°ìˆ ì  ì§€í‘œ** - MA, RSI, ATR, Bollinger Bands (ë³‘ë ¬ ì²˜ë¦¬)\n",
    "4. **ì‹œì¥ ì»¨í…ìŠ¤íŠ¸** - SPY/QQQ/VIX ê°­, ì„¹í„°ë³„ ê°­\n",
    "\n",
    "### ğŸ”´ ì•„ì§ êµ¬í˜„ ì•ˆ ëœ ê²ƒ\n",
    "- ì‹¤ì  ë°œí‘œ ë°ì´í„° (earnings)\n",
    "- ë‰´ìŠ¤/ì„¼í‹°ë¨¼íŠ¸ ë°ì´í„°\n",
    "- ì• ë„ë¦¬ìŠ¤íŠ¸ ë ˆì´íŒ… ë°ì´í„°\n",
    "- í”„ë¦¬ë§ˆì¼“ ë°ì´í„° (Phase 2)\n",
    "\n",
    "### ğŸš€ ì „ì²´ ì¢…ëª© ì‹¤í–‰ ë°©ë²•\n",
    "ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•˜ë©´, ìœ„ ì½”ë“œì—ì„œ:\n",
    "- `sample_stocks = stock_list_full.head(10)` â†’ `sample_stocks = stock_list_full`\n",
    "- `start_date = datetime.now() - timedelta(days=365 * 2)` â†’ `days=365 * 10` (10ë…„)\n",
    "\n",
    "### ğŸ“Š ëª¨ë¸ë§ ì¤€ë¹„\n",
    "- `df_final`ì„ ì‚¬ìš©í•˜ì—¬ ë°”ë¡œ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥\n",
    "- ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§: `df_final[df_final['is_gap_up'] == 1]`\n",
    "- Train/Valid/Test ë¶„í•  í›„ ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 99. [ì°¸ê³ ]QQQ/VIX ì¸ë±ìŠ¤ í™•ì¸\n",
    "\n",
    "QQQì™€ VIX ë°ì´í„°ë¥¼ ëª» ê°€ì ¸ì˜¨ ì´ìœ ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBì— ìˆëŠ” ì¸ë±ìŠ¤ ë‹ˆëª¨ë‹‰ í™•ì¸\n",
    "from src.data.models import DS2EquityIndex\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DBì— ìˆëŠ” ì¸ë±ìŠ¤ ë‹ˆëª¨ë‹‰ í™•ì¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with DatabaseConnector() as db:\n",
    "    with SessionManager(db) as session:\n",
    "        # 1. NASDAQ ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n1. NASDAQ ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        nasdaq_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%NASD%')\n",
    "        ).limit(10).all()\n",
    "        \n",
    "        if nasdaq_indices:\n",
    "            for idx in nasdaq_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ NASDAQ ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 2. QQQ ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n2. QQQ ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        qqq_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%QQQ%')\n",
    "        ).limit(10).all()\n",
    "        \n",
    "        if qqq_indices:\n",
    "            for idx in qqq_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ QQQ ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 3. VIX ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n3. VIX ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        vix_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%VIX%')\n",
    "        ).limit(10).all()\n",
    "        \n",
    "        if vix_indices:\n",
    "            for idx in vix_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ VIX ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 4. CBOE ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n4. CBOE ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        cboe_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%CBOE%')\n",
    "        ).limit(10).all()\n",
    "        \n",
    "        if cboe_indices:\n",
    "            for idx in cboe_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ CBOE ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 5. S&P ê´€ë ¨ ì¸ë±ìŠ¤ í™•ì¸ (ì„±ê³µí•œ ê²ƒ)\n",
    "        print(\"\\n5. S&P ê´€ë ¨ ì¸ë±ìŠ¤ (ì„±ê³µí•œ ê²ƒ):\")\n",
    "        sp_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%S&P%')\n",
    "        ).limit(10).all()\n",
    "        \n",
    "        if sp_indices:\n",
    "            for idx in sp_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ S&P ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 6. ìƒ˜í”Œë¡œ ì²˜ìŒ 20ê°œ ì¸ë±ìŠ¤ ì¶œë ¥\n",
    "        print(\"\\n6. ìƒ˜í”Œ: DBì˜ ì²˜ìŒ 20ê°œ ì¸ë±ìŠ¤\")\n",
    "        sample_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).limit(20).all()\n",
    "        \n",
    "        for idx in sample_indices:\n",
    "            print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASDAQ 100/Composite ì¸ë±ìŠ¤ ìƒì„¸ ê²€ìƒ‰\n",
    "print(\"=\"*80)\n",
    "print(\"NASDAQ ì¸ë±ìŠ¤ ìƒì„¸ ê²€ìƒ‰\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with DatabaseConnector() as db:\n",
    "    with SessionManager(db) as session:\n",
    "        # 1. IndexDescì—ì„œ NASDAQ ê²€ìƒ‰\n",
    "        print(\"\\n1. IndexDescì— 'NASDAQ' í¬í•¨:\")\n",
    "        nasdaq_all = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.IndexDesc.like('%NASDAQ%')\n",
    "        ).limit(30).all()\n",
    "        \n",
    "        if nasdaq_all:\n",
    "            for idx in nasdaq_all:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem:12s} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ NASDAQ ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 2. NDX ê²€ìƒ‰ (NASDAQ 100ì˜ í‹°ì»¤)\n",
    "        print(\"\\n2. NDX ê²€ìƒ‰:\")\n",
    "        ndx_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%NDX%')\n",
    "        ).limit(10).all()\n",
    "        \n",
    "        if ndx_indices:\n",
    "            for idx in ndx_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ NDX ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 3. COMP ê²€ìƒ‰ (Composite)\n",
    "        print(\"\\n3. COMP ê²€ìƒ‰:\")\n",
    "        comp_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%COMP%')\n",
    "        ).limit(15).all()\n",
    "        \n",
    "        if comp_indices:\n",
    "            for idx in comp_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ COMP ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100. [ì°¸ê³ ] í•œêµ­ ì£¼ì‹ ì¸ë±ìŠ¤ í™•ì¸\n",
    "\n",
    "KOSPI, KOSDAQ, KRX ë“± í•œêµ­ ì£¼ì‹ ê´€ë ¨ ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBì— ìˆëŠ” ì¸ë±ìŠ¤ ë‹ˆëª¨ë‹‰ í™•ì¸\n",
    "from src.data.models import DS2EquityIndex, DS2Exchange, DS2CtryQtInfo, DS2PrimQtPrc,RKDFndInfo\n",
    "# í•œêµ­ ì£¼ì‹ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "print(\"=\"*80)\n",
    "print(\"DBì— ìˆëŠ” í•œêµ­ ì£¼ì‹ ì¸ë±ìŠ¤ í™•ì¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with DatabaseConnector() as db:\n",
    "    with SessionManager(db) as session:\n",
    "        # 1. KOSPI ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n1. KOSPI ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        kospi_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%KOSPI%')\n",
    "        ).limit(20).all()\n",
    "        \n",
    "        if kospi_indices:\n",
    "            for idx in kospi_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem:20s} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ KOSPI ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 2. KOSDAQ ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n2. KOSDAQ ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        kosdaq_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%KOS%')\n",
    "        ).limit(20).all()\n",
    "        \n",
    "        if kosdaq_indices:\n",
    "            for idx in kosdaq_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem:20s} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ KOSDAQ ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 3. KRX ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n3. KRX ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        krx_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%KRX%')\n",
    "        ).limit(20).all()\n",
    "        \n",
    "        if krx_indices:\n",
    "            for idx in krx_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem:20s} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ KRX ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 4. KOREA/KOR ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n4. KOREA ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        korea_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%KOR%')\n",
    "        ).limit(20).all()\n",
    "        \n",
    "        if korea_indices:\n",
    "            for idx in korea_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem:20s} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ KOREA ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 5. IndexDescì—ì„œ Korea ê²€ìƒ‰ (ì„¤ëª…ì—ì„œ ê²€ìƒ‰)\n",
    "        print(\"\\n5. IndexDescì— 'Korea' í¬í•¨:\")\n",
    "        korea_desc_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.IndexDesc.like('%Korea%')\n",
    "        ).limit(30).all()\n",
    "        \n",
    "        if korea_desc_indices:\n",
    "            for idx in korea_desc_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem:20s} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ Korea ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")\n",
    "        \n",
    "        # 6. Seoul/SEO ê´€ë ¨ ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
    "        print(\"\\n6. Seoul/SEO ê´€ë ¨ ì¸ë±ìŠ¤:\")\n",
    "        seoul_indices = session.query(\n",
    "            DS2EquityIndex.DSIndexCode,\n",
    "            DS2EquityIndex.DSIndexMnem,\n",
    "            DS2EquityIndex.IndexDesc\n",
    "        ).filter(\n",
    "            DS2EquityIndex.DSIndexMnem.like('%SEO%')\n",
    "        ).limit(20).all()\n",
    "        \n",
    "        if seoul_indices:\n",
    "            for idx in seoul_indices:\n",
    "                print(f\"   {idx.DSIndexCode}: {idx.DSIndexMnem:20s} - {idx.IndexDesc}\")\n",
    "        else:\n",
    "            print(\"   âŒ Seoul/SEO ê´€ë ¨ ì¸ë±ìŠ¤ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ ê±°ë˜ì†Œ ë° ì¢…ëª© ë¦¬ìŠ¤íŠ¸ í™•ì¸\n",
    "print(\"=\"*80)\n",
    "print(\"í•œêµ­ ê±°ë˜ì†Œ ë° ì¢…ëª© ë¦¬ìŠ¤íŠ¸ í™•ì¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with DatabaseConnector() as db:\n",
    "    with SessionManager(db) as session:\n",
    "        # 1. í•œêµ­ ê±°ë˜ì†Œ í™•ì¸\n",
    "        print(\"\\n[1] í•œêµ­ ê±°ë˜ì†Œ ëª©ë¡:\")\n",
    "        korea_exchanges = session.query(DS2Exchange).filter(\n",
    "            DS2Exchange.ExchCtryCode == 'KR'\n",
    "        ).all()\n",
    "        \n",
    "        if korea_exchanges:\n",
    "            for exch in korea_exchanges:\n",
    "                print(f\"   - {exch.ExchName} (ì½”ë“œ: {exch.ExchIntCode}, Mnem: {exch.ExchMnem})\")\n",
    "            \n",
    "            korea_exch_codes = [exch.ExchIntCode for exch in korea_exchanges]\n",
    "            \n",
    "            # 2. í•œêµ­ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (ìƒ˜í”Œ)\n",
    "            print(f\"\\n[2] í•œêµ­ ì¢…ëª© ì¡°íšŒ ì¤‘...\")\n",
    "            \n",
    "            korea_stocks = session.query(\n",
    "                DS2CtryQtInfo.InfoCode,\n",
    "                DS2CtryQtInfo.DsCode,\n",
    "                DS2CtryQtInfo.DsQtName,\n",
    "                DS2CtryQtInfo.StatusCode,\n",
    "                DS2PrimQtPrc.ExchIntCode,\n",
    "                DS2Exchange.ExchName,\n",
    "                DS2Exchange.ExchMnem,\n",
    "                RKDFndInfo.Ticker,\n",
    "                RKDFndInfo.ISIN,\n",
    "            ).join(\n",
    "                DS2PrimQtPrc,\n",
    "                DS2CtryQtInfo.InfoCode == DS2PrimQtPrc.InfoCode\n",
    "            ).join(\n",
    "                DS2Exchange,\n",
    "                DS2PrimQtPrc.ExchIntCode == DS2Exchange.ExchIntCode\n",
    "            ).outerjoin(\n",
    "                RKDFndInfo, \n",
    "                DS2CtryQtInfo.InfoCode == RKDFndInfo.Code\n",
    "            ).filter(\n",
    "                and_(\n",
    "                    DS2CtryQtInfo.Region == 'KR',\n",
    "                    DS2CtryQtInfo.IsPrimQt == 1,\n",
    "                    DS2PrimQtPrc.ExchIntCode.in_(korea_exch_codes)\n",
    "                )\n",
    "            ).distinct().limit(50).all()\n",
    "            \n",
    "            print(f\"âœ“ ì¡°íšŒëœ í•œêµ­ ì¢…ëª© ìˆ˜: {len(korea_stocks)} (ìƒ˜í”Œ 50ê°œ)\")\n",
    "            \n",
    "            # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "            df_korea_stocks = pd.DataFrame([\n",
    "                {\n",
    "                    'InfoCode': s.InfoCode,\n",
    "                    'DsCode': s.DsCode,\n",
    "                    'DsQtName': s.DsQtName,\n",
    "                    'Exchange': s.ExchName,\n",
    "                    'ExchMnem': s.ExchMnem,\n",
    "                    'Ticker': s.Ticker,\n",
    "                    'ISIN': s.ISIN,\n",
    "                    'StatusCode': s.StatusCode,\n",
    "                }\n",
    "                for s in korea_stocks\n",
    "            ])\n",
    "            \n",
    "            print(f\"\\nâœ“ í•œêµ­ ì¢…ëª© ë°ì´í„°í”„ë ˆì„:\")\n",
    "            print(f\"  - Shape: {df_korea_stocks.shape}\")\n",
    "            if len(df_korea_stocks) > 0:\n",
    "                print(f\"  - Ticker ë§¤í•‘ë¥ : {df_korea_stocks['Ticker'].notna().sum()}/{len(df_korea_stocks)}\")\n",
    "                print(f\"  - ISIN ë§¤í•‘ë¥ : {df_korea_stocks['ISIN'].notna().sum()}/{len(df_korea_stocks)}\")\n",
    "            \n",
    "            print(\"\\nìƒ˜í”Œ ë°ì´í„°:\")\n",
    "            display(df_korea_stocks.head(20))\n",
    "        else:\n",
    "            print(\"   âŒ í•œêµ­ ê±°ë˜ì†Œ ì •ë³´ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì´ìƒì¹˜ ì œê±° (IQR ë°©ë²•)\n",
    "\n",
    "DB ì ê²€ ì¤‘ì´ë¯€ë¡œ ê¸°ì¡´ parquet íŒŒì¼ì—ì„œ ì½ì–´ì„œ IQR ì´ìƒì¹˜ ì œê±° ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IQR ì´ìƒì¹˜ ì œê±°\n",
      "================================================================================\n",
      "\n",
      "âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n",
      "  - Shape: (151825, 68)\n",
      "  - ë‚ ì§œ ë²”ìœ„: 2006-01-17 00:00:00 ~ 2026-01-08 00:00:00\n",
      "  - ì¢…ëª© ìˆ˜: 2,250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\n",
    "print(\"=\" * 80)\n",
    "print(\"IQR ì´ìƒì¹˜ ì œê±°\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_final = pd.read_parquet(\"../data/processed/preprocessed_df_full.parquet\")\n",
    "print(f\"\\nâœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"  - Shape: {df_final.shape}\")\n",
    "print(f\"  - ë‚ ì§œ ë²”ìœ„: {df_final['date'].min()} ~ {df_final['date'].max()}\")\n",
    "print(f\"  - ì¢…ëª© ìˆ˜: {df_final['InfoCode'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ IQR ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 2. IQR ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ ì •ì˜\n",
    "def remove_outliers_iqr(df, columns, multiplier=1.5, verbose=True):\n",
    "    \"\"\"\n",
    "    IQR (Interquartile Range) ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ ì œê±°\n",
    "    \n",
    "    ê³µì‹:\n",
    "    - Q1 = 25th percentile\n",
    "    - Q3 = 75th percentile\n",
    "    - IQR = Q3 - Q1\n",
    "    - Lower Bound = Q1 - multiplier * IQR\n",
    "    - Upper Bound = Q3 + multiplier * IQR\n",
    "    \"\"\"\n",
    "    # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "    columns = [c for c in columns if c in df.columns]\n",
    "    \n",
    "    if not columns:\n",
    "        print(\"   âš  IQR ì ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return df\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n=== IQR ì´ìƒì¹˜ ì œê±° (multiplier={multiplier}) ===\")\n",
    "        print(f\"ì ìš© ì»¬ëŸ¼: {len(columns)}ê°œ\")\n",
    "    \n",
    "    # ê° ì»¬ëŸ¼ë³„ë¡œ ì´ìƒì¹˜ ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    outlier_mask = pd.Series(False, index=df_clean.index)\n",
    "    col_stats = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if df_clean[col].isna().all():\n",
    "            continue\n",
    "            \n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "        \n",
    "        # ì´ìƒì¹˜ íŒë³„\n",
    "        col_outliers = (df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)\n",
    "        outlier_count = col_outliers.sum()\n",
    "        \n",
    "        if outlier_count > 0:\n",
    "            col_stats.append({\n",
    "                'column': col,\n",
    "                'Q1': Q1,\n",
    "                'Q3': Q3,\n",
    "                'IQR': IQR,\n",
    "                'lower': lower_bound,\n",
    "                'upper': upper_bound,\n",
    "                'outliers': outlier_count,\n",
    "                'pct': outlier_count / len(df_clean) * 100\n",
    "            })\n",
    "        \n",
    "        # ì „ì²´ ì´ìƒì¹˜ ë§ˆìŠ¤í¬ì— í•©ì¹˜ê¸°\n",
    "        outlier_mask = outlier_mask | col_outliers\n",
    "    \n",
    "    # ì´ìƒì¹˜ ì œê±°\n",
    "    df_clean = df_clean[~outlier_mask].copy()\n",
    "    \n",
    "    final_count = len(df_clean)\n",
    "    removed_count = initial_count - final_count\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nì»¬ëŸ¼ë³„ ì´ìƒì¹˜ í†µê³„:\")\n",
    "        for stat in sorted(col_stats, key=lambda x: x['outliers'], reverse=True)[:10]:\n",
    "            print(f\"  - {stat['column']}: {stat['outliers']:,}ê°œ ({stat['pct']:.2f}%) \"\n",
    "                  f\"[ë²”ìœ„: {stat['lower']:.2f} ~ {stat['upper']:.2f}]\")\n",
    "        \n",
    "        if len(col_stats) > 10:\n",
    "            print(f\"  ... ì™¸ {len(col_stats) - 10}ê°œ ì»¬ëŸ¼\")\n",
    "        \n",
    "        print(f\"\\nâœ“ ì´ìƒì¹˜ ì œê±°: {initial_count:,} â†’ {final_count:,} \"\n",
    "              f\"({removed_count:,}ê°œ ì œê±°, {removed_count/initial_count*100:.2f}%)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "print(\"âœ“ IQR ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ìƒì¹˜ ì œê±° ëŒ€ìƒ ì»¬ëŸ¼: 15ê°œ\n",
      "  - Feature: 13ê°œ\n",
      "  - Target: 2ê°œ\n"
     ]
    }
   ],
   "source": [
    "# 3. ì´ìƒì¹˜ ì œê±° ëŒ€ìƒ ì»¬ëŸ¼ ì •ì˜ (ì—°ì†í˜• Feature + Target)\n",
    "CONTINUOUS_FEATURE_COLS = [\n",
    "    # ê°­ ê´€ë ¨\n",
    "    'gap_pct',\n",
    "    \n",
    "    # ì „ì¼ íŒ¨í„´\n",
    "    'prev_return', 'prev_range_pct', 'prev_upper_shadow', 'prev_lower_shadow',\n",
    "    \n",
    "    # ê±°ë˜ëŸ‰\n",
    "    'volume_ratio',\n",
    "    \n",
    "    # ê¸°ìˆ ì  ì§€í‘œ\n",
    "    'rsi_14', 'atr_14', 'atr_ratio', 'bollinger_position',\n",
    "    'return_5d', 'return_20d',\n",
    "    \n",
    "    # ì‹œì¥ ì»¨í…ìŠ¤íŠ¸\n",
    "    'market_gap_diff',\n",
    "]\n",
    "\n",
    "TARGET_COLS = [\n",
    "    'target_return', 'target_max_return'\n",
    "]\n",
    "\n",
    "outlier_columns = CONTINUOUS_FEATURE_COLS + TARGET_COLS\n",
    "print(f\"ì´ìƒì¹˜ ì œê±° ëŒ€ìƒ ì»¬ëŸ¼: {len(outlier_columns)}ê°œ\")\n",
    "print(f\"  - Feature: {len(CONTINUOUS_FEATURE_COLS)}ê°œ\")\n",
    "print(f\"  - Target: {len(TARGET_COLS)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì´ìƒì¹˜ í˜„í™© (ì œê±° ì „)\n",
      "================================================================================\n",
      "\n",
      "ì´ ì´ìƒì¹˜ í˜„í™©:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>Q1</th>\n",
       "      <th>median</th>\n",
       "      <th>Q3</th>\n",
       "      <th>IQR</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>outliers</th>\n",
       "      <th>outlier_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>volume_ratio</td>\n",
       "      <td>0.493929</td>\n",
       "      <td>0.876955</td>\n",
       "      <td>1.701204</td>\n",
       "      <td>1.207275</td>\n",
       "      <td>-1.316983</td>\n",
       "      <td>3.512116</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>19.545603</td>\n",
       "      <td>14194</td>\n",
       "      <td>9.348921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gap_pct</td>\n",
       "      <td>3.508772</td>\n",
       "      <td>4.376083</td>\n",
       "      <td>6.373293</td>\n",
       "      <td>2.864521</td>\n",
       "      <td>-0.788009</td>\n",
       "      <td>10.670074</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13368</td>\n",
       "      <td>8.804874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>market_gap_diff</td>\n",
       "      <td>2.962252</td>\n",
       "      <td>4.285297</td>\n",
       "      <td>6.535363</td>\n",
       "      <td>3.573111</td>\n",
       "      <td>-2.397414</td>\n",
       "      <td>11.895030</td>\n",
       "      <td>-9.231893</td>\n",
       "      <td>27.310934</td>\n",
       "      <td>12137</td>\n",
       "      <td>7.994072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>atr_14</td>\n",
       "      <td>442.304025</td>\n",
       "      <td>888.295549</td>\n",
       "      <td>1913.912723</td>\n",
       "      <td>1471.608698</td>\n",
       "      <td>-1765.109021</td>\n",
       "      <td>4121.325769</td>\n",
       "      <td>1.674620</td>\n",
       "      <td>96205.501025</td>\n",
       "      <td>11258</td>\n",
       "      <td>7.415116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prev_return</td>\n",
       "      <td>-2.307692</td>\n",
       "      <td>0.652529</td>\n",
       "      <td>4.736842</td>\n",
       "      <td>7.044534</td>\n",
       "      <td>-12.874494</td>\n",
       "      <td>15.303644</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>206.060606</td>\n",
       "      <td>10001</td>\n",
       "      <td>6.587189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prev_upper_shadow</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965079</td>\n",
       "      <td>8513</td>\n",
       "      <td>5.607113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>target_return</td>\n",
       "      <td>-5.217391</td>\n",
       "      <td>-2.345416</td>\n",
       "      <td>1.480263</td>\n",
       "      <td>6.697654</td>\n",
       "      <td>-15.263873</td>\n",
       "      <td>11.526745</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>236.842105</td>\n",
       "      <td>8334</td>\n",
       "      <td>5.489215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prev_lower_shadow</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.021260</td>\n",
       "      <td>-0.028356</td>\n",
       "      <td>0.056683</td>\n",
       "      <td>-0.061759</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>7780</td>\n",
       "      <td>5.124321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>atr_ratio</td>\n",
       "      <td>0.140915</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.355345</td>\n",
       "      <td>0.214430</td>\n",
       "      <td>-0.180730</td>\n",
       "      <td>0.676989</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>11.897822</td>\n",
       "      <td>7684</td>\n",
       "      <td>5.061090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>return_20d</td>\n",
       "      <td>-42.105263</td>\n",
       "      <td>-0.917599</td>\n",
       "      <td>64.120061</td>\n",
       "      <td>106.225324</td>\n",
       "      <td>-201.443249</td>\n",
       "      <td>223.458047</td>\n",
       "      <td>-99.936316</td>\n",
       "      <td>18349.905482</td>\n",
       "      <td>6897</td>\n",
       "      <td>4.542730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>target_max_return</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>6.967213</td>\n",
       "      <td>6.528617</td>\n",
       "      <td>-9.354328</td>\n",
       "      <td>16.760138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>610.526316</td>\n",
       "      <td>6622</td>\n",
       "      <td>4.361601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prev_range_pct</td>\n",
       "      <td>4.824561</td>\n",
       "      <td>7.645260</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>7.370561</td>\n",
       "      <td>-6.231279</td>\n",
       "      <td>23.250963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>233.333333</td>\n",
       "      <td>5748</td>\n",
       "      <td>3.785938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>return_5d</td>\n",
       "      <td>-24.878493</td>\n",
       "      <td>-1.077061</td>\n",
       "      <td>29.843398</td>\n",
       "      <td>54.721891</td>\n",
       "      <td>-106.961329</td>\n",
       "      <td>111.926235</td>\n",
       "      <td>-99.689592</td>\n",
       "      <td>5813.793103</td>\n",
       "      <td>5419</td>\n",
       "      <td>3.569241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rsi_14</td>\n",
       "      <td>40.281620</td>\n",
       "      <td>47.730917</td>\n",
       "      <td>56.718117</td>\n",
       "      <td>16.436497</td>\n",
       "      <td>15.626875</td>\n",
       "      <td>81.372863</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2863</td>\n",
       "      <td>1.885724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bollinger_position</td>\n",
       "      <td>0.232671</td>\n",
       "      <td>0.420163</td>\n",
       "      <td>0.711359</td>\n",
       "      <td>0.478688</td>\n",
       "      <td>-0.485360</td>\n",
       "      <td>1.429391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column          Q1      median           Q3          IQR  \\\n",
       "5         volume_ratio    0.493929    0.876955     1.701204     1.207275   \n",
       "0              gap_pct    3.508772    4.376083     6.373293     2.864521   \n",
       "12     market_gap_diff    2.962252    4.285297     6.535363     3.573111   \n",
       "7               atr_14  442.304025  888.295549  1913.912723  1471.608698   \n",
       "1          prev_return   -2.307692    0.652529     4.736842     7.044534   \n",
       "3    prev_upper_shadow    0.000000    0.013825     0.033333     0.033333   \n",
       "13       target_return   -5.217391   -2.345416     1.480263     6.697654   \n",
       "4    prev_lower_shadow    0.003534    0.012195     0.024793     0.021260   \n",
       "8            atr_ratio    0.140915    0.225852     0.355345     0.214430   \n",
       "11          return_20d  -42.105263   -0.917599    64.120061   106.225324   \n",
       "14   target_max_return    0.438596    2.777778     6.967213     6.528617   \n",
       "2       prev_range_pct    4.824561    7.645260    12.195122     7.370561   \n",
       "10           return_5d  -24.878493   -1.077061    29.843398    54.721891   \n",
       "6               rsi_14   40.281620   47.730917    56.718117    16.436497   \n",
       "9   bollinger_position    0.232671    0.420163     0.711359     0.478688   \n",
       "\n",
       "    lower_bound  upper_bound        min           max  outliers  outlier_pct  \n",
       "5     -1.316983     3.512116   0.000002     19.545603     14194     9.348921  \n",
       "0     -0.788009    10.670074   3.000000     20.000000     13368     8.804874  \n",
       "12    -2.397414    11.895030  -9.231893     27.310934     12137     7.994072  \n",
       "7  -1765.109021  4121.325769   1.674620  96205.501025     11258     7.415116  \n",
       "1    -12.874494    15.303644 -70.000000    206.060606     10001     6.587189  \n",
       "3     -0.050000     0.083333   0.000000      0.965079      8513     5.607113  \n",
       "13   -15.263873    11.526745 -66.666667    236.842105      8334     5.489215  \n",
       "4     -0.028356     0.056683  -0.061759      0.356061      7780     5.124321  \n",
       "8     -0.180730     0.676989   0.000353     11.897822      7684     5.061090  \n",
       "11  -201.443249   223.458047 -99.936316  18349.905482      6897     4.542730  \n",
       "14    -9.354328    16.760138   0.000000    610.526316      6622     4.361601  \n",
       "2     -6.231279    23.250963   0.000000    233.333333      5748     3.785938  \n",
       "10  -106.961329   111.926235 -99.689592   5813.793103      5419     3.569241  \n",
       "6     15.626875    81.372863   0.335100    100.000000      2863     1.885724  \n",
       "9     -0.485360     1.429391   0.000000      1.000000         0     0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. ì´ìƒì¹˜ í˜„í™© í™•ì¸ (ì œê±° ì „)\n",
    "print(\"=\" * 80)\n",
    "print(\"ì´ìƒì¹˜ í˜„í™© (ì œê±° ì „)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "outlier_summary = []\n",
    "for col in outlier_columns:\n",
    "    if col not in df_final.columns or df_final[col].isna().all():\n",
    "        continue\n",
    "    \n",
    "    Q1 = df_final[col].quantile(0.25)\n",
    "    Q3 = df_final[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = ((df_final[col] < lower) | (df_final[col] > upper)).sum()\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'column': col,\n",
    "        'Q1': Q1,\n",
    "        'median': df_final[col].median(),\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'lower_bound': lower,\n",
    "        'upper_bound': upper,\n",
    "        'min': df_final[col].min(),\n",
    "        'max': df_final[col].max(),\n",
    "        'outliers': outliers,\n",
    "        'outlier_pct': outliers / len(df_final) * 100,\n",
    "    })\n",
    "\n",
    "df_outlier_summary = pd.DataFrame(outlier_summary).sort_values('outlier_pct', ascending=False)\n",
    "print(f\"\\nì´ ì´ìƒì¹˜ í˜„í™©:\")\n",
    "display(df_outlier_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IQR ì´ìƒì¹˜ ì œê±° ì‹¤í–‰\n",
      "================================================================================\n",
      "\n",
      "=== IQR ì´ìƒì¹˜ ì œê±° (multiplier=1.5) ===\n",
      "ì ìš© ì»¬ëŸ¼: 15ê°œ\n",
      "\n",
      "ì»¬ëŸ¼ë³„ ì´ìƒì¹˜ í†µê³„:\n",
      "  - volume_ratio: 14,194ê°œ (9.35%) [ë²”ìœ„: -1.32 ~ 3.51]\n",
      "  - gap_pct: 13,368ê°œ (8.80%) [ë²”ìœ„: -0.79 ~ 10.67]\n",
      "  - market_gap_diff: 12,137ê°œ (7.99%) [ë²”ìœ„: -2.40 ~ 11.90]\n",
      "  - atr_14: 11,258ê°œ (7.42%) [ë²”ìœ„: -1765.11 ~ 4121.33]\n",
      "  - prev_return: 10,001ê°œ (6.59%) [ë²”ìœ„: -12.87 ~ 15.30]\n",
      "  - prev_upper_shadow: 8,513ê°œ (5.61%) [ë²”ìœ„: -0.05 ~ 0.08]\n",
      "  - target_return: 8,334ê°œ (5.49%) [ë²”ìœ„: -15.26 ~ 11.53]\n",
      "  - prev_lower_shadow: 7,780ê°œ (5.12%) [ë²”ìœ„: -0.03 ~ 0.06]\n",
      "  - atr_ratio: 7,684ê°œ (5.06%) [ë²”ìœ„: -0.18 ~ 0.68]\n",
      "  - return_20d: 6,897ê°œ (4.54%) [ë²”ìœ„: -201.44 ~ 223.46]\n",
      "  ... ì™¸ 4ê°œ ì»¬ëŸ¼\n",
      "\n",
      "âœ“ ì´ìƒì¹˜ ì œê±°: 151,825 â†’ 88,699 (63,126ê°œ ì œê±°, 41.58%)\n",
      "\n",
      "ìµœì¢… ê²°ê³¼:\n",
      "  - ì›ë³¸: 151,825ê°œ\n",
      "  - ì •ì œ: 88,699ê°œ\n",
      "  - ì œê±°ë¨: 63,126ê°œ (41.58%)\n"
     ]
    }
   ],
   "source": [
    "# 5. IQR ì´ìƒì¹˜ ì œê±° ì‹¤í–‰\n",
    "print(\"=\" * 80)\n",
    "print(\"IQR ì´ìƒì¹˜ ì œê±° ì‹¤í–‰\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_clean = remove_outliers_iqr(\n",
    "    df_final, \n",
    "    columns=outlier_columns, \n",
    "    multiplier=1.5,  # ì¼ë°˜ì ì¸ ì´ìƒì¹˜ ì œê±° (ë” ê´€ëŒ€í•˜ê²Œ í•˜ë ¤ë©´ 3.0 ì‚¬ìš©)\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nìµœì¢… ê²°ê³¼:\")\n",
    "print(f\"  - ì›ë³¸: {len(df_final):,}ê°œ\")\n",
    "print(f\"  - ì •ì œ: {len(df_clean):,}ê°œ\")\n",
    "print(f\"  - ì œê±°ë¨: {len(df_final) - len(df_clean):,}ê°œ ({(len(df_final) - len(df_clean))/len(df_final)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ë°ì´í„° ì €ì¥ ì™„ë£Œ\n",
      "================================================================================\n",
      "\n",
      "âœ“ ì €ì¥ ê²½ë¡œ: ../data/processed/preprocessed_df_full_outlier_fix.parquet\n",
      "âœ“ íŒŒì¼ í¬ê¸°: 21.65 MB\n",
      "âœ“ ë°ì´í„° Shape: (88699, 68)\n",
      "âœ“ ë‚ ì§œ ë²”ìœ„: 2006-01-17 00:00:00 ~ 2026-01-08 00:00:00\n",
      "âœ“ ì¢…ëª© ìˆ˜: 2,225\n"
     ]
    }
   ],
   "source": [
    "# 6. ì´ìƒì¹˜ ì œê±°ëœ ë°ì´í„° ì €ì¥\n",
    "output_path = \"../data/processed/preprocessed_df_full_outlier_fix.parquet\"\n",
    "\n",
    "df_clean.to_parquet(output_path, index=False)\n",
    "\n",
    "import os\n",
    "file_size = os.path.getsize(output_path) / 1024 / 1024\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ë°ì´í„° ì €ì¥ ì™„ë£Œ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ“ ì €ì¥ ê²½ë¡œ: {output_path}\")\n",
    "print(f\"âœ“ íŒŒì¼ í¬ê¸°: {file_size:.2f} MB\")\n",
    "print(f\"âœ“ ë°ì´í„° Shape: {df_clean.shape}\")\n",
    "print(f\"âœ“ ë‚ ì§œ ë²”ìœ„: {df_clean['date'].min()} ~ {df_clean['date'].max()}\")\n",
    "print(f\"âœ“ ì¢…ëª© ìˆ˜: {df_clean['InfoCode'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì´ìƒì¹˜ ì œê±° ì „í›„ í†µê³„ ë¹„êµ\n",
      "================================================================================\n",
      "\n",
      "[gap_pct]\n",
      "  ì œê±° ì „: min=3.00, max=20.00, mean=5.63, std=3.19\n",
      "  ì œê±° í›„: min=3.00, max=10.67, mean=4.62, std=1.64\n",
      "\n",
      "[prev_return]\n",
      "  ì œê±° ì „: min=-70.00, max=206.06, mean=1.90, std=7.79\n",
      "  ì œê±° í›„: min=-12.87, max=15.30, mean=0.81, std=5.12\n",
      "\n",
      "[target_return]\n",
      "  ì œê±° ì „: min=-66.67, max=236.84, mean=-1.62, std=6.93\n",
      "  ì œê±° í›„: min=-15.26, max=11.52, mean=-1.75, std=4.83\n",
      "\n",
      "[target_max_return]\n",
      "  ì œê±° ì „: min=0.00, max=610.53, mean=4.56, std=5.75\n",
      "  ì œê±° í›„: min=0.00, max=16.76, mean=3.59, std=3.76\n",
      "\n",
      "[volume_ratio]\n",
      "  ì œê±° ì „: min=0.00, max=19.55, mean=1.48, std=1.75\n",
      "  ì œê±° í›„: min=0.00, max=3.51, mean=0.94, std=0.70\n",
      "\n",
      "================================================================================\n",
      "âœ“ ì´ìƒì¹˜ ì œê±° ì™„ë£Œ!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 7. ì œê±° ì „í›„ ë¹„êµ (ì£¼ìš” ì»¬ëŸ¼)\n",
    "print(\"=\" * 80)\n",
    "print(\"ì´ìƒì¹˜ ì œê±° ì „í›„ í†µê³„ ë¹„êµ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "compare_cols = ['gap_pct', 'prev_return', 'target_return', 'target_max_return', 'volume_ratio']\n",
    "compare_cols = [c for c in compare_cols if c in df_final.columns]\n",
    "\n",
    "for col in compare_cols:\n",
    "    print(f\"\\n[{col}]\")\n",
    "    print(f\"  ì œê±° ì „: min={df_final[col].min():.2f}, max={df_final[col].max():.2f}, mean={df_final[col].mean():.2f}, std={df_final[col].std():.2f}\")\n",
    "    print(f\"  ì œê±° í›„: min={df_clean[col].min():.2f}, max={df_clean[col].max():.2f}, mean={df_clean[col].mean():.2f}, std={df_clean[col].std():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ ì´ìƒì¹˜ ì œê±° ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price-predict-eVNULRoT-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
