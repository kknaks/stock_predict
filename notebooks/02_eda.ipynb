{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)\n",
    "\n",
    "Phase 2: EDA ë° Feature Engineering\n",
    "\n",
    "## ëª©í‘œ\n",
    "- 2.1 ê°­ ìƒìŠ¹ ê¸°ì´ˆ í†µê³„ ë¶„ì„ (ì—°ë„ë³„/ì›”ë³„ ë¹ˆë„, ê°­ í¬ê¸° ë¶„í¬)\n",
    "- 2.2 íƒ€ê²Ÿ ë¶„í¬ ë¶„ì„ (ì „ì²´ ìŠ¹ë¥ , ê°­ í¬ê¸°ë³„ ìŠ¹ë¥ )\n",
    "- 2.3 Feature ìƒê´€ê´€ê³„ ë° Feature Importance ì˜ˆë¹„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ê·¸ë˜í”„ ìŠ¤íƒ€ì¼\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"korea.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ\n",
    "data_path = \"../data/processed/preprocessed_df_full.parquet\"\n",
    "\n",
    "print(f\"ë°ì´í„° ë¡œë“œ ì¤‘: {data_path}\")\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"\\nâœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"  - Shape: {df.shape}\")\n",
    "print(f\"  - ë‚ ì§œ ë²”ìœ„: {df['date'].min()} ~ {df['date'].max()}\")\n",
    "print(f\"  - ì¢…ëª© ìˆ˜: {df['InfoCode'].nunique():,}\")\n",
    "print(f\"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸\n",
    "print(\"=\" * 80)\n",
    "print(\"ë°ì´í„° ê¸°ë³¸ ì •ë³´\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nì „ì²´ ì»¬ëŸ¼ ({len(df.columns)}ê°œ):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col:30s} - dtype: {df[col].dtype}\")\n",
    "\n",
    "print(f\"\\në°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ê°­ ìƒìŠ¹ ê¸°ì´ˆ í†µê³„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ì „ì²´ ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ í•„í„°ë§\n",
    "df_gap_up = df[df['is_gap_up'] == 1].copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ì „ì²´ ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ í†µê³„\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nì „ì²´ ê±°ë˜ì¼ ìˆ˜: {len(df):,}\")\n",
    "print(f\"ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ ìˆ˜: {len(df_gap_up):,}\")\n",
    "print(f\"ê°­ ìƒìŠ¹ ë¹„ìœ¨: {len(df_gap_up)/len(df)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nê°­ ìƒìŠ¹ë¥  ë¶„í¬:\")\n",
    "print(df_gap_up['gap_pct'].describe())\n",
    "\n",
    "print(f\"\\nê°­ í¬ê¸° ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:\")\n",
    "gap_category_counts = df_gap_up['gap_size_category'].value_counts().sort_index()\n",
    "for category, count in gap_category_counts.items():\n",
    "    pct = count / len(df_gap_up) * 100\n",
    "    print(f\"  {category:10s}: {count:8,} ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°­ ìƒìŠ¹ë¥  ë¶„í¬ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# íˆìŠ¤í† ê·¸ë¨\n",
    "axes[0].hist(df_gap_up['gap_pct'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df_gap_up['gap_pct'].mean(), color='red', linestyle='--', \n",
    "                label=f\"Mean: {df_gap_up['gap_pct'].mean():.2f}%\")\n",
    "axes[0].axvline(df_gap_up['gap_pct'].median(), color='green', linestyle='--', \n",
    "                label=f\"Median: {df_gap_up['gap_pct'].median():.2f}%\")\n",
    "axes[0].set_xlabel('Gap Percentage (%)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Gap Up Distribution (Histogram)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot (ê°­ í¬ê¸° ì¹´í…Œê³ ë¦¬ë³„)\n",
    "df_gap_up.boxplot(column='gap_pct', by='gap_size_category', ax=axes[1])\n",
    "axes[1].set_xlabel('Gap Size Category')\n",
    "axes[1].set_ylabel('Gap Percentage (%)')\n",
    "axes[1].set_title('Gap Distribution by Size Category')\n",
    "plt.suptitle('')  # ê¸°ë³¸ ì œëª© ì œê±°\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ì—°ë„ë³„ ê°­ ë°œìƒ ë¹ˆë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°ë„ë³„ ê°­ ë°œìƒ ë¹ˆë„\n",
    "yearly_gaps = df_gap_up.groupby('year').agg({\n",
    "    'InfoCode': 'count',  # ê°­ ì´ë²¤íŠ¸ ìˆ˜\n",
    "    'gap_pct': ['mean', 'median'],\n",
    "    'target_direction': 'mean'  # ìŠ¹ë¥ \n",
    "}).round(2)\n",
    "\n",
    "yearly_gaps.columns = ['Gap_Events', 'Avg_Gap_Pct', 'Median_Gap_Pct', 'Win_Rate']\n",
    "yearly_gaps['Win_Rate'] = (yearly_gaps['Win_Rate'] * 100).round(1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ì—°ë„ë³„ ê°­ ìƒìŠ¹ í†µê³„\")\n",
    "print(\"=\" * 80)\n",
    "print(yearly_gaps)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ì—°ë„ë³„ ê°­ ì´ë²¤íŠ¸ ìˆ˜\n",
    "axes[0, 0].bar(yearly_gaps.index, yearly_gaps['Gap_Events'], alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Year')\n",
    "axes[0, 0].set_ylabel('Number of Gap Events')\n",
    "axes[0, 0].set_title('Gap Up Events by Year')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ì—°ë„ë³„ í‰ê·  ê°­ ìƒìŠ¹ë¥ \n",
    "axes[0, 1].plot(yearly_gaps.index, yearly_gaps['Avg_Gap_Pct'], marker='o', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Year')\n",
    "axes[0, 1].set_ylabel('Average Gap (%)')\n",
    "axes[0, 1].set_title('Average Gap Percentage by Year')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ì—°ë„ë³„ ìŠ¹ë¥ \n",
    "axes[1, 0].plot(yearly_gaps.index, yearly_gaps['Win_Rate'], marker='o', \n",
    "                color='green', linewidth=2)\n",
    "axes[1, 0].axhline(50, color='red', linestyle='--', label='50% baseline')\n",
    "axes[1, 0].set_xlabel('Year')\n",
    "axes[1, 0].set_ylabel('Win Rate (%)')\n",
    "axes[1, 0].set_title('Win Rate by Year')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ì—°ë„ë³„ Median Gap\n",
    "axes[1, 1].plot(yearly_gaps.index, yearly_gaps['Median_Gap_Pct'], marker='o', \n",
    "                color='orange', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Median Gap (%)')\n",
    "axes[1, 1].set_title('Median Gap Percentage by Year')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ì›”ë³„ ê°­ ë°œìƒ ë¹ˆë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›”ë³„ ê°­ ë°œìƒ ë¹ˆë„\n",
    "monthly_gaps = df_gap_up.groupby('month').agg({\n",
    "    'InfoCode': 'count',\n",
    "    'gap_pct': ['mean', 'median'],\n",
    "    'target_direction': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "monthly_gaps.columns = ['Gap_Events', 'Avg_Gap_Pct', 'Median_Gap_Pct', 'Win_Rate']\n",
    "monthly_gaps['Win_Rate'] = (monthly_gaps['Win_Rate'] * 100).round(1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ì›”ë³„ ê°­ ìƒìŠ¹ í†µê³„\")\n",
    "print(\"=\" * 80)\n",
    "print(monthly_gaps)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ì›”ë³„ ê°­ ì´ë²¤íŠ¸ ìˆ˜\n",
    "axes[0].bar(monthly_gaps.index, monthly_gaps['Gap_Events'], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Number of Gap Events')\n",
    "axes[0].set_title('Gap Up Events by Month')\n",
    "axes[0].set_xticks(range(1, 13))\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ì›”ë³„ ìŠ¹ë¥ \n",
    "axes[1].plot(monthly_gaps.index, monthly_gaps['Win_Rate'], marker='o', \n",
    "             color='green', linewidth=2)\n",
    "axes[1].axhline(50, color='red', linestyle='--', label='50% baseline')\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Win Rate (%)')\n",
    "axes[1].set_title('Win Rate by Month')\n",
    "axes[1].set_xticks(range(1, 13))\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ìš”ì¼ë³„ ê°­ ë°œìƒ ë¹ˆë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš”ì¼ë³„ ê°­ ë°œìƒ ë¹ˆë„\n",
    "weekday_gaps = df_gap_up.groupby('day_of_week').agg({\n",
    "    'InfoCode': 'count',\n",
    "    'gap_pct': ['mean', 'median'],\n",
    "    'target_direction': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "weekday_gaps.columns = ['Gap_Events', 'Avg_Gap_Pct', 'Median_Gap_Pct', 'Win_Rate']\n",
    "weekday_gaps['Win_Rate'] = (weekday_gaps['Win_Rate'] * 100).round(1)\n",
    "weekday_gaps.index = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ìš”ì¼ë³„ ê°­ ìƒìŠ¹ í†µê³„\")\n",
    "print(\"=\" * 80)\n",
    "print(weekday_gaps)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ìš”ì¼ë³„ ê°­ ì´ë²¤íŠ¸ ìˆ˜\n",
    "axes[0].bar(range(5), weekday_gaps['Gap_Events'], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Day of Week')\n",
    "axes[0].set_ylabel('Number of Gap Events')\n",
    "axes[0].set_title('Gap Up Events by Day of Week')\n",
    "axes[0].set_xticks(range(5))\n",
    "axes[0].set_xticklabels(weekday_gaps.index, rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ìš”ì¼ë³„ ìŠ¹ë¥ \n",
    "axes[1].plot(range(5), weekday_gaps['Win_Rate'], marker='o', \n",
    "             color='green', linewidth=2)\n",
    "axes[1].axhline(50, color='red', linestyle='--', label='50% baseline')\n",
    "axes[1].set_xlabel('Day of Week')\n",
    "axes[1].set_ylabel('Win Rate (%)')\n",
    "axes[1].set_title('Win Rate by Day of Week')\n",
    "axes[1].set_xticks(range(5))\n",
    "axes[1].set_xticklabels(weekday_gaps.index, rotation=45)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. íƒ€ê²Ÿ ë¶„í¬ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ì „ì²´ ê°­ ìƒìŠ¹ í›„ ìŠ¹ë¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ì „ì²´ ê°­ ìƒìŠ¹ íƒ€ê²Ÿ ë¶„í¬\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ì „ì²´ ìŠ¹ë¥ \n",
    "win_rate = df_gap_up['target_direction'].mean() * 100\n",
    "wins = df_gap_up['target_direction'].sum()\n",
    "losses = len(df_gap_up) - wins\n",
    "\n",
    "print(f\"\\nì „ì²´ ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸: {len(df_gap_up):,}\")\n",
    "print(f\"  - ìƒìŠ¹ (ì¢…ê°€ > ì‹œê°€): {wins:,} ({win_rate:.2f}%)\")\n",
    "print(f\"  - í•˜ë½ (ì¢…ê°€ â‰¤ ì‹œê°€): {losses:,} ({100-win_rate:.2f}%)\")\n",
    "\n",
    "# ìˆ˜ìµë¥  í†µê³„\n",
    "print(f\"\\në‹¹ì¼ ìˆ˜ìµë¥  í†µê³„:\")\n",
    "print(df_gap_up['target_return'].describe())\n",
    "\n",
    "# ìƒìŠ¹/í•˜ë½ë³„ ìˆ˜ìµë¥ \n",
    "df_up = df_gap_up[df_gap_up['target_direction'] == 1]\n",
    "df_down = df_gap_up[df_gap_up['target_direction'] == 0]\n",
    "\n",
    "print(f\"\\nìƒìŠ¹ ì‹œ í‰ê·  ìˆ˜ìµë¥ : {df_up['target_return'].mean():.2f}%\")\n",
    "print(f\"í•˜ë½ ì‹œ í‰ê·  ì†ì‹¤ë¥ : {df_down['target_return'].mean():.2f}%\")\n",
    "\n",
    "# ê¸°ëŒ€ ìˆ˜ìµë¥ \n",
    "expected_return = df_gap_up['target_return'].mean()\n",
    "print(f\"\\nê¸°ëŒ€ ìˆ˜ìµë¥ : {expected_return:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿ ë¶„í¬ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# íƒ€ê²Ÿ ë°©í–¥ ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)\n",
    "target_counts = df_gap_up['target_direction'].value_counts()\n",
    "axes[0].pie(target_counts, labels=['Down (0)', 'Up (1)'], autopct='%1.1f%%', \n",
    "            startangle=90, colors=['lightcoral', 'lightgreen'])\n",
    "axes[0].set_title(f'Target Direction Distribution\\n(Win Rate: {win_rate:.1f}%)')\n",
    "\n",
    "# ìˆ˜ìµë¥  ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)\n",
    "axes[1].hist(df_gap_up['target_return'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Break-even')\n",
    "axes[1].axvline(expected_return, color='green', linestyle='--', linewidth=2, \n",
    "                label=f'Expected: {expected_return:.2f}%')\n",
    "axes[1].set_xlabel('Intraday Return (%)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Intraday Return Distribution')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# ìƒìŠ¹/í•˜ë½ë³„ ìˆ˜ìµë¥  ë¶„í¬ (Box plot)\n",
    "df_gap_up_with_label = df_gap_up.copy()\n",
    "df_gap_up_with_label['direction_label'] = df_gap_up_with_label['target_direction'].map({0: 'Down', 1: 'Up'})\n",
    "df_gap_up_with_label.boxplot(column='target_return', by='direction_label', ax=axes[2])\n",
    "axes[2].set_xlabel('Target Direction')\n",
    "axes[2].set_ylabel('Intraday Return (%)')\n",
    "axes[2].set_title('Return Distribution by Direction')\n",
    "plt.suptitle('')  # ê¸°ë³¸ ì œëª© ì œê±°\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ê°­ í¬ê¸°ë³„ ìŠ¹ë¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°­ í¬ê¸°ë³„ ìŠ¹ë¥ \n",
    "gap_size_stats = df_gap_up.groupby('gap_size_category').agg({\n",
    "    'InfoCode': 'count',\n",
    "    'target_direction': 'mean',\n",
    "    'target_return': ['mean', 'std'],\n",
    "    'gap_pct': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "gap_size_stats.columns = ['Count', 'Win_Rate', 'Avg_Return', 'Std_Return', 'Avg_Gap']\n",
    "gap_size_stats['Win_Rate'] = (gap_size_stats['Win_Rate'] * 100).round(1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ê°­ í¬ê¸°ë³„ ì„±ê³¼ ë¶„ì„\")\n",
    "print(\"=\" * 80)\n",
    "print(gap_size_stats)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ê°­ í¬ê¸°ë³„ ìŠ¹ë¥ \n",
    "gap_categories = gap_size_stats.index.astype(str)\n",
    "axes[0].bar(range(len(gap_categories)), gap_size_stats['Win_Rate'], \n",
    "            alpha=0.7, edgecolor='black', color='green')\n",
    "axes[0].axhline(50, color='red', linestyle='--', label='50% baseline')\n",
    "axes[0].set_xlabel('Gap Size Category')\n",
    "axes[0].set_ylabel('Win Rate (%)')\n",
    "axes[0].set_title('Win Rate by Gap Size')\n",
    "axes[0].set_xticks(range(len(gap_categories)))\n",
    "axes[0].set_xticklabels(gap_categories)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ê°­ í¬ê¸°ë³„ í‰ê·  ìˆ˜ìµë¥ \n",
    "axes[1].bar(range(len(gap_categories)), gap_size_stats['Avg_Return'], \n",
    "            alpha=0.7, edgecolor='black', color='blue')\n",
    "axes[1].axhline(0, color='red', linestyle='--', label='Break-even')\n",
    "axes[1].set_xlabel('Gap Size Category')\n",
    "axes[1].set_ylabel('Average Return (%)')\n",
    "axes[1].set_title('Average Return by Gap Size')\n",
    "axes[1].set_xticks(range(len(gap_categories)))\n",
    "axes[1].set_xticklabels(gap_categories)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ê°­ ìƒìŠ¹ë¥  êµ¬ê°„ë³„ ìŠ¹ë¥  (ì„¸ë¶„í™”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°­ ìƒìŠ¹ë¥ ì„ ë” ì„¸ë¶„í™”ëœ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "bins = [0, 1, 2, 3, 5, 10, 50]\n",
    "labels = ['0-1%', '1-2%', '2-3%', '3-5%', '5-10%', '10%+']\n",
    "\n",
    "df_gap_up['gap_bin'] = pd.cut(df_gap_up['gap_pct'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "gap_bin_stats = df_gap_up.groupby('gap_bin', observed=False).agg({\n",
    "    'InfoCode': 'count',\n",
    "    'target_direction': 'mean',\n",
    "    'target_return': 'mean',\n",
    "    'gap_pct': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "gap_bin_stats.columns = ['Count', 'Win_Rate', 'Avg_Return', 'Avg_Gap']\n",
    "gap_bin_stats['Win_Rate'] = (gap_bin_stats['Win_Rate'] * 100).round(1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ê°­ ìƒìŠ¹ë¥  êµ¬ê°„ë³„ ì„±ê³¼ ë¶„ì„\")\n",
    "print(\"=\" * 80)\n",
    "print(gap_bin_stats)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# êµ¬ê°„ë³„ ì´ë²¤íŠ¸ ìˆ˜ì™€ ìŠ¹ë¥ \n",
    "x_pos = range(len(gap_bin_stats))\n",
    "axes[0].bar(x_pos, gap_bin_stats['Count'], alpha=0.5, label='Count', edgecolor='black')\n",
    "ax0_twin = axes[0].twinx()\n",
    "ax0_twin.plot(x_pos, gap_bin_stats['Win_Rate'], 'ro-', linewidth=2, markersize=8, label='Win Rate')\n",
    "ax0_twin.axhline(50, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "axes[0].set_xlabel('Gap Percentage Range')\n",
    "axes[0].set_ylabel('Count', color='blue')\n",
    "ax0_twin.set_ylabel('Win Rate (%)', color='red')\n",
    "axes[0].set_title('Count and Win Rate by Gap Range')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(gap_bin_stats.index, rotation=45)\n",
    "axes[0].legend(loc='upper left')\n",
    "ax0_twin.legend(loc='upper right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# êµ¬ê°„ë³„ í‰ê·  ìˆ˜ìµë¥ \n",
    "axes[1].bar(x_pos, gap_bin_stats['Avg_Return'], alpha=0.7, edgecolor='black')\n",
    "axes[1].axhline(0, color='red', linestyle='--', label='Break-even')\n",
    "axes[1].set_xlabel('Gap Percentage Range')\n",
    "axes[1].set_ylabel('Average Return (%)')\n",
    "axes[1].set_title('Average Return by Gap Range')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(gap_bin_stats.index, rotation=45)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ì„¹í„°ë³„ ìŠ¹ë¥  (ì„¹í„° ì •ë³´ê°€ ìˆëŠ” ê²½ìš°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¹í„° ì •ë³´ í™•ì¸\n",
    "sector_coverage = df_gap_up['sector'].notna().sum() / len(df_gap_up) * 100\n",
    "\n",
    "print(f\"ì„¹í„° ì •ë³´ ì»¤ë²„ë¦¬ì§€: {sector_coverage:.1f}%\")\n",
    "\n",
    "if sector_coverage > 10:  # 10% ì´ìƒ ì»¤ë²„ë˜ë©´ ë¶„ì„\n",
    "    sector_stats = df_gap_up[df_gap_up['sector'].notna()].groupby('sector').agg({\n",
    "        'InfoCode': 'count',\n",
    "        'target_direction': 'mean',\n",
    "        'target_return': 'mean',\n",
    "        'gap_pct': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    sector_stats.columns = ['Count', 'Win_Rate', 'Avg_Return', 'Avg_Gap']\n",
    "    sector_stats['Win_Rate'] = (sector_stats['Win_Rate'] * 100).round(1)\n",
    "    sector_stats = sector_stats.sort_values('Count', ascending=False)\n",
    "    \n",
    "    print(\"\\n=\" * 80)\n",
    "    print(\"ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„ (ìƒìœ„ 10ê°œ)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(sector_stats.head(10))\n",
    "    \n",
    "    # ì‹œê°í™” (ìƒìœ„ 10ê°œ ì„¹í„°)\n",
    "    top_sectors = sector_stats.head(10)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # ì„¹í„°ë³„ ìŠ¹ë¥ \n",
    "    axes[0].barh(range(len(top_sectors)), top_sectors['Win_Rate'], alpha=0.7, edgecolor='black')\n",
    "    axes[0].axvline(50, color='red', linestyle='--', label='50% baseline')\n",
    "    axes[0].set_xlabel('Win Rate (%)')\n",
    "    axes[0].set_ylabel('Sector')\n",
    "    axes[0].set_title('Win Rate by Sector (Top 10)')\n",
    "    axes[0].set_yticks(range(len(top_sectors)))\n",
    "    axes[0].set_yticklabels(top_sectors.index)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ì„¹í„°ë³„ í‰ê·  ìˆ˜ìµë¥ \n",
    "    axes[1].barh(range(len(top_sectors)), top_sectors['Avg_Return'], alpha=0.7, edgecolor='black')\n",
    "    axes[1].axvline(0, color='red', linestyle='--', label='Break-even')\n",
    "    axes[1].set_xlabel('Average Return (%)')\n",
    "    axes[1].set_ylabel('Sector')\n",
    "    axes[1].set_title('Average Return by Sector (Top 10)')\n",
    "    axes[1].set_yticks(range(len(top_sectors)))\n",
    "    axes[1].set_yticklabels(top_sectors.index)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nâš  ì„¹í„° ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„ì„ ìƒëµí•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature ìƒê´€ê´€ê³„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ìˆ˜ì¹˜í˜• Feature ì„ íƒ ë° ìƒê´€ê´€ê³„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì¹˜í˜• Feature ì„ íƒ (ê°­ ìƒìŠ¹ ë°ì´í„°ë§Œ)\n",
    "numeric_features = [\n",
    "    # ê°­ ê´€ë ¨\n",
    "    'gap_pct',\n",
    "    \n",
    "    # ì „ì¼ íŒ¨í„´\n",
    "    'prev_return', 'prev_range_pct', 'prev_upper_shadow', 'prev_lower_shadow',\n",
    "    \n",
    "    # ê±°ë˜ëŸ‰\n",
    "    'volume_ratio',\n",
    "    \n",
    "    # ê¸°ìˆ ì  ì§€í‘œ\n",
    "    'rsi_14', 'atr_14', 'atr_ratio', 'bollinger_position',\n",
    "    'return_5d', 'return_20d', 'consecutive_up_days',\n",
    "    \n",
    "    # ì‹œì¥ ì»¨í…ìŠ¤íŠ¸\n",
    "    'spy_gap_pct', 'qqq_gap_pct', 'market_gap_diff',\n",
    "    \n",
    "    # íƒ€ê²Ÿ\n",
    "    'target_direction', 'target_return'\n",
    "]\n",
    "\n",
    "# ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "available_features = [f for f in numeric_features if f in df_gap_up.columns]\n",
    "\n",
    "print(f\"ë¶„ì„ ê°€ëŠ¥í•œ ìˆ˜ì¹˜í˜• Features: {len(available_features)}ê°œ\")\n",
    "print(f\"\\nFeature ë¦¬ìŠ¤íŠ¸:\")\n",
    "for i, feat in enumerate(available_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒê´€ê´€ê³„ ê³„ì‚°\n",
    "correlation_matrix = df_gap_up[available_features].corr()\n",
    "\n",
    "# íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„ (target_direction)\n",
    "target_corr = correlation_matrix['target_direction'].sort_values(ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"íƒ€ê²Ÿ(target_direction)ê³¼ì˜ ìƒê´€ê´€ê³„\")\n",
    "print(\"=\" * 80)\n",
    "print(target_corr)\n",
    "\n",
    "# ìƒìœ„/í•˜ìœ„ Feature í‘œì‹œ\n",
    "print(f\"\\nìƒìœ„ 5ê°œ (ì–‘ì˜ ìƒê´€ê´€ê³„):\")\n",
    "print(target_corr.head(6)[1:])  # target_direction ìì‹  ì œì™¸\n",
    "\n",
    "print(f\"\\ní•˜ìœ„ 5ê°œ (ìŒì˜ ìƒê´€ê´€ê³„):\")\n",
    "print(target_corr.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„ ë°” ì°¨íŠ¸\n",
    "target_corr_plot = target_corr.drop('target_direction')  # ìê¸° ìì‹  ì œì™¸\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in target_corr_plot.values]\n",
    "plt.barh(range(len(target_corr_plot)), target_corr_plot.values, color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.yticks(range(len(target_corr_plot)), target_corr_plot.index)\n",
    "plt.xlabel('Correlation with target_direction')\n",
    "plt.title('Feature Correlation with Target Direction', fontsize=14)\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature ê°„ ìƒê´€ê´€ê³„ (ë‹¤ì¤‘ê³µì„ ì„± í™•ì¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature ê°„ ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸° (ì ˆëŒ“ê°’ > 0.7)\n",
    "print(\"=\" * 80)\n",
    "print(\"Feature ê°„ ë†’ì€ ìƒê´€ê´€ê³„ (|r| > 0.7)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append((\n",
    "                correlation_matrix.columns[i],\n",
    "                correlation_matrix.columns[j],\n",
    "                correlation_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs, columns=['Feature_1', 'Feature_2', 'Correlation'])\n",
    "    high_corr_df = high_corr_df.sort_values('Correlation', ascending=False, key=abs)\n",
    "    print(high_corr_df)\n",
    "    print(f\"\\nâš  ë‹¤ì¤‘ê³µì„ ì„± ê°€ëŠ¥ì„±: {len(high_corr_pairs)}ê°œ ìŒ ë°œê²¬\")\n",
    "else:\n",
    "    print(\"\\nâœ“ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ Feature ìŒì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ì£¼ìš” Feature ì‚°ì ë„ (íƒ€ê²Ÿê³¼ì˜ ê´€ê³„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íƒ€ê²Ÿê³¼ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ìƒìœ„ 6ê°œ Feature ì„ íƒ\n",
    "top_features = target_corr.drop('target_direction').head(6).index.tolist()\n",
    "\n",
    "# ì‚°ì ë„ ê·¸ë¦¬ê¸°\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë¦¼)\n",
    "    sample_size = min(10000, len(df_gap_up))\n",
    "    df_sample = df_gap_up.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # íƒ€ê²Ÿë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„\n",
    "    up_mask = df_sample['target_direction'] == 1\n",
    "    down_mask = df_sample['target_direction'] == 0\n",
    "    \n",
    "    axes[idx].scatter(df_sample[down_mask][feature], df_sample[down_mask]['target_return'], \n",
    "                      alpha=0.3, s=10, c='red', label='Down')\n",
    "    axes[idx].scatter(df_sample[up_mask][feature], df_sample[up_mask]['target_return'], \n",
    "                      alpha=0.3, s=10, c='green', label='Up')\n",
    "    \n",
    "    axes[idx].axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('target_return')\n",
    "    axes[idx].set_title(f'{feature} vs target_return\\n(corr: {target_corr[feature]:.3f})')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance ì˜ˆë¹„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ê°„ë‹¨í•œ Tree ëª¨ë¸ë¡œ Feature Importance í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# NaN ì œê±° ë° í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
    "feature_cols = [f for f in available_features if f not in ['target_direction', 'target_return']]\n",
    "df_model = df_gap_up[feature_cols + ['target_direction']].dropna()\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„° Shape: {df_model.shape}\")\n",
    "print(f\"Feature ê°œìˆ˜: {len(feature_cols)}\")\n",
    "\n",
    "if len(df_model) > 100:  # ìµœì†Œ ë°ì´í„° í™•ì¸\n",
    "    X = df_model[feature_cols]\n",
    "    y = df_model['target_direction']\n",
    "    \n",
    "    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "    print(f\"\\ní´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "    print(f\"  í•˜ë½(0): {(y==0).sum():,} ({(y==0).sum()/len(y)*100:.1f}%)\")\n",
    "    print(f\"  ìƒìŠ¹(1): {(y==1).sum():,} ({(y==1).sum()/len(y)*100:.1f}%)\")\n",
    "    \n",
    "    # Train/Test ë¶„í• \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTrain set: {len(X_train):,}\")\n",
    "    print(f\"Test set: {len(X_test):,}\")\n",
    "    \n",
    "    # Random Forest í•™ìŠµ (ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°)\n",
    "    print(\"\\n=== Random Forest í•™ìŠµ (ê°œì„  ë²„ì „) ===\")\n",
    "    print(\"í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
    "    print(\"  - n_estimators: 300 (100 â†’ 300)\")\n",
    "    print(\"  - max_depth: 15 (10 â†’ 15)\")\n",
    "    print(\"  - min_samples_split: 10\")\n",
    "    print(\"  - class_weight: 'balanced'\")\n",
    "    print(\"  - Optimal Threshold: 0.4 (ë¶„ì„ ê²°ê³¼ ë°˜ì˜)\")\n",
    "    \n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=300,           # íŠ¸ë¦¬ ê°œìˆ˜ ì¦ê°€\n",
    "        max_depth=15,                # ê¹Šì´ ì¦ê°€\n",
    "        min_samples_split=10,        # ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
    "        class_weight='balanced',     # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì„±ëŠ¥ í‰ê°€\n",
    "    train_acc = rf_model.score(X_train, y_train)\n",
    "    test_acc = rf_model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"\\nâœ“ í•™ìŠµ ì™„ë£Œ\")\n",
    "    print(f\"  Train Accuracy: {train_acc:.3f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.3f}\")\n",
    "    \n",
    "    # ì˜ˆì¸¡ (Threshold 0.5 ê¸°ë³¸)\n",
    "    y_pred_default = rf_model.predict(X_test)\n",
    "    y_proba = rf_model.predict_proba(X_test)[:, 1]  # ìƒìŠ¹ í™•ë¥ \n",
    "    \n",
    "    # ì˜ˆì¸¡ (Threshold 0.4 ìµœì )\n",
    "    y_pred_optimal = (y_proba >= 0.4).astype(int)\n",
    "    \n",
    "    # === Threshold 0.5 (ê¸°ë³¸) ê²°ê³¼ ===\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š Threshold 0.5 (ê¸°ë³¸ê°’) ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    cm_default = confusion_matrix(y_test, y_pred_default)\n",
    "    print(\"\\ní˜¼ë™ í–‰ë ¬:\")\n",
    "    print(cm_default)\n",
    "    print(f\"\\nì‹¤ì œ í•˜ë½ ì¤‘ í•˜ë½ ì˜ˆì¸¡: {cm_default[0,0]:,} / {cm_default[0].sum():,} ({cm_default[0,0]/cm_default[0].sum()*100:.1f}%)\")\n",
    "    print(f\"ì‹¤ì œ ìƒìŠ¹ ì¤‘ ìƒìŠ¹ ì˜ˆì¸¡: {cm_default[1,1]:,} / {cm_default[1].sum():,} ({cm_default[1,1]/cm_default[1].sum()*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\në¶„ë¥˜ ì„±ëŠ¥:\")\n",
    "    print(classification_report(y_test, y_pred_default, target_names=['í•˜ë½(0)', 'ìƒìŠ¹(1)']))\n",
    "    \n",
    "    # === Threshold 0.4 (ìµœì ) ê²°ê³¼ ===\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"â­ Threshold 0.4 (ìµœì ê°’) ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    cm_optimal = confusion_matrix(y_test, y_pred_optimal)\n",
    "    print(\"\\ní˜¼ë™ í–‰ë ¬:\")\n",
    "    print(cm_optimal)\n",
    "    print(f\"\\nì‹¤ì œ í•˜ë½ ì¤‘ í•˜ë½ ì˜ˆì¸¡: {cm_optimal[0,0]:,} / {cm_optimal[0].sum():,} ({cm_optimal[0,0]/cm_optimal[0].sum()*100:.1f}%)\")\n",
    "    print(f\"ì‹¤ì œ ìƒìŠ¹ ì¤‘ ìƒìŠ¹ ì˜ˆì¸¡: {cm_optimal[1,1]:,} / {cm_optimal[1].sum():,} ({cm_optimal[1,1]/cm_optimal[1].sum()*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\në¶„ë¥˜ ì„±ëŠ¥:\")\n",
    "    print(classification_report(y_test, y_pred_optimal, target_names=['í•˜ë½(0)', 'ìƒìŠ¹(1)']))\n",
    "    \n",
    "    # === Feature Importance ===\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Feature Importance (Random Forest)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # ë¹„êµ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ìš”ì•½\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    \n",
    "    # Threshold 0.5\n",
    "    precision_05 = precision_score(y_test, y_pred_default, pos_label=1)\n",
    "    recall_05 = recall_score(y_test, y_pred_default, pos_label=1)\n",
    "    f1_05 = f1_score(y_test, y_pred_default, pos_label=1)\n",
    "    \n",
    "    # Threshold 0.4\n",
    "    precision_04 = precision_score(y_test, y_pred_optimal, pos_label=1)\n",
    "    recall_04 = recall_score(y_test, y_pred_optimal, pos_label=1)\n",
    "    f1_04 = f1_score(y_test, y_pred_optimal, pos_label=1)\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Threshold': [0.5, 0.4],\n",
    "        'Precision': [precision_05, precision_04],\n",
    "        'Recall': [recall_05, recall_04],\n",
    "        'F1-Score': [f1_05, f1_04],\n",
    "        'Predicted_Positive': [y_pred_default.sum(), y_pred_optimal.sum()]\n",
    "    })\n",
    "    \n",
    "    print(comparison.to_string(index=False))\n",
    "    print(f\"\\nâœ… ì¶”ì²œ: Threshold 0.4 ì‚¬ìš©\")\n",
    "    print(f\"   - Recall {recall_04*100:.1f}%ë¡œ ìƒìŠ¹ì˜ ëŒ€ë¶€ë¶„ í¬ì°©\")\n",
    "    print(f\"   - F1-Score {f1_04:.3f}ë¡œ ê· í˜• ìµœì \")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    feature_importance = None\n",
    "    rf_model = None\n",
    "    y_proba = None\n",
    "    y_pred_optimal = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance ì‹œê°í™”\n",
    "if feature_importance is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(feature_importance)), feature_importance['importance'], \n",
    "             alpha=0.7, edgecolor='black')\n",
    "    plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance (Random Forest)', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ìƒìœ„ 10ê°œ Feature\n",
    "    print(\"\\nìƒìœ„ 10ê°œ ì¤‘ìš”í•œ Features:\")\n",
    "    for idx, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"  {row['feature']:25s}: {row['importance']:.4f}\")\n",
    "\n",
    "# ROC ê³¡ì„  ë° Precision-Recall ê³¡ì„ \n",
    "if rf_model is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 1. ROC ê³¡ì„ \n",
    "    fpr, tpr, thresholds_roc = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Baseline')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title('ROC Curve')\n",
    "    axes[0].legend(loc=\"lower right\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Precision-Recall ê³¡ì„ \n",
    "    precision, recall, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
    "    \n",
    "    axes[1].plot(recall, precision, color='blue', lw=2)\n",
    "    axes[1].axhline(y=(y_test==1).sum()/len(y_test), color='red', linestyle='--', \n",
    "                    label=f'Baseline ({(y_test==1).sum()/len(y_test):.3f})')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('Recall')\n",
    "    axes[1].set_ylabel('Precision')\n",
    "    axes[1].set_title('Precision-Recall Curve')\n",
    "    axes[1].legend(loc=\"upper right\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nROC AUC Score: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold ì¡°ì • ì‹¤í—˜\n",
    "if rf_model is not None:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Threshold ì¡°ì • ì‹¤í—˜\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\në‹¤ì–‘í•œ Thresholdì—ì„œì˜ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "    print(f\"{'Threshold':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'ì˜ˆì¸¡ ìƒìŠ¹ ìˆ˜':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    threshold_results = []\n",
    "    for threshold in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "        \n",
    "        # ìƒìŠ¹(1) í´ë˜ìŠ¤ì— ëŒ€í•œ ì§€í‘œë§Œ ê³„ì‚°\n",
    "        from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "        \n",
    "        precision = precision_score(y_test, y_pred_thresh, pos_label=1, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred_thresh, pos_label=1)\n",
    "        f1 = f1_score(y_test, y_pred_thresh, pos_label=1, zero_division=0)\n",
    "        predicted_positive = y_pred_thresh.sum()\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': threshold,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'predicted_positive': predicted_positive\n",
    "        })\n",
    "        \n",
    "        print(f\"{threshold:<12.1f} {precision:<12.3f} {recall:<12.3f} {f1:<12.3f} {predicted_positive:<12,}\")\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    df_thresh = pd.DataFrame(threshold_results)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # ì¢Œ: Precision, Recall, F1-Score vs Threshold\n",
    "    axes[0].plot(df_thresh['threshold'], df_thresh['precision'], 'o-', label='Precision', linewidth=2, markersize=8)\n",
    "    axes[0].plot(df_thresh['threshold'], df_thresh['recall'], 's-', label='Recall', linewidth=2, markersize=8)\n",
    "    axes[0].plot(df_thresh['threshold'], df_thresh['f1'], '^-', label='F1-Score', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Threshold')\n",
    "    axes[0].set_ylabel('Score')\n",
    "    axes[0].set_title('Performance Metrics vs Threshold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xlim([0.15, 0.75])\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    \n",
    "    # ìš°: ì˜ˆì¸¡ëœ ìƒìŠ¹ ê°œìˆ˜ vs Threshold\n",
    "    axes[1].bar(df_thresh['threshold'], df_thresh['predicted_positive'], alpha=0.7, edgecolor='black')\n",
    "    axes[1].axhline(y=(y_test==1).sum(), color='red', linestyle='--', linewidth=2, \n",
    "                    label=f'ì‹¤ì œ ìƒìŠ¹ ìˆ˜: {(y_test==1).sum():,}')\n",
    "    axes[1].set_xlabel('Threshold')\n",
    "    axes[1].set_ylabel('Predicted Positive Count')\n",
    "    axes[1].set_title('Predicted Positive Count vs Threshold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ìµœì  Threshold ì°¾ê¸° (F1-Score ê¸°ì¤€)\n",
    "    best_idx = df_thresh['f1'].idxmax()\n",
    "    best_threshold = df_thresh.loc[best_idx, 'threshold']\n",
    "    best_f1 = df_thresh.loc[best_idx, 'f1']\n",
    "    \n",
    "    print(f\"\\nìµœì  Threshold (F1-Score ê¸°ì¤€): {best_threshold:.1f}\")\n",
    "    print(f\"  - F1-Score: {best_f1:.3f}\")\n",
    "    print(f\"  - Precision: {df_thresh.loc[best_idx, 'precision']:.3f}\")\n",
    "    print(f\"  - Recall: {df_thresh.loc[best_idx, 'recall']:.3f}\")\n",
    "    \n",
    "    # ìµœì  Thresholdë¡œ ì¬í‰ê°€\n",
    "    y_pred_optimal = (y_proba >= best_threshold).astype(int)\n",
    "    cm_optimal = confusion_matrix(y_test, y_pred_optimal)\n",
    "    \n",
    "    print(f\"\\nìµœì  Threshold({best_threshold:.1f})ì—ì„œì˜ í˜¼ë™ í–‰ë ¬:\")\n",
    "    print(cm_optimal)\n",
    "    print(f\"\\nì‹¤ì œ ìƒìŠ¹ ì¤‘ ìƒìŠ¹ ì˜ˆì¸¡: {cm_optimal[1,1]:,} / {cm_optimal[1].sum():,} ({cm_optimal[1,1]/cm_optimal[1].sum()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ìš”ì•½ ë° ì¸ì‚¬ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EDA ìš”ì•½\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n1. ë°ì´í„° ê°œìš”\")\n",
    "print(f\"   - ì „ì²´ ê±°ë˜ì¼: {len(df):,}\")\n",
    "print(f\"   - ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸: {len(df_gap_up):,} ({len(df_gap_up)/len(df)*100:.1f}%)\")\n",
    "print(f\"   - ê¸°ê°„: {df['date'].min().date()} ~ {df['date'].max().date()}\")\n",
    "print(f\"   - ì¢…ëª© ìˆ˜: {df['InfoCode'].nunique():,}\")\n",
    "\n",
    "print(f\"\\n2. ê°­ ìƒìŠ¹ í†µê³„\")\n",
    "print(f\"   - í‰ê·  ê°­ ìƒìŠ¹ë¥ : {df_gap_up['gap_pct'].mean():.2f}%\")\n",
    "print(f\"   - ì¤‘ê°„ ê°­ ìƒìŠ¹ë¥ : {df_gap_up['gap_pct'].median():.2f}%\")\n",
    "print(f\"   - ìµœëŒ€ ê°­ ìƒìŠ¹ë¥ : {df_gap_up['gap_pct'].max():.2f}%\")\n",
    "\n",
    "print(f\"\\n3. íƒ€ê²Ÿ ë¶„ì„\")\n",
    "print(f\"   - ì „ì²´ ìŠ¹ë¥ : {df_gap_up['target_direction'].mean()*100:.2f}%\")\n",
    "print(f\"   - í‰ê·  ìˆ˜ìµë¥ : {df_gap_up['target_return'].mean():.2f}%\")\n",
    "print(f\"   - ìƒìŠ¹ ì‹œ í‰ê·  ìˆ˜ìµë¥ : {df_up['target_return'].mean():.2f}%\")\n",
    "print(f\"   - í•˜ë½ ì‹œ í‰ê·  ì†ì‹¤ë¥ : {df_down['target_return'].mean():.2f}%\")\n",
    "\n",
    "print(f\"\\n4. ì£¼ìš” ì¸ì‚¬ì´íŠ¸\")\n",
    "print(f\"   - ê°­ í¬ê¸°ê°€ í´ìˆ˜ë¡ ìŠ¹ë¥ ì´ {'ë†’ìŠµë‹ˆë‹¤' if gap_size_stats['Win_Rate'].is_monotonic_increasing else 'ë‚®ìŠµë‹ˆë‹¤'}\")\n",
    "print(f\"   - ì›”ìš”ì¼ ê°­ ìƒìŠ¹ ì´ë²¤íŠ¸ê°€ {'ë§ìŠµë‹ˆë‹¤' if weekday_gaps['Gap_Events'].idxmax() == 'Monday' else 'ì ìŠµë‹ˆë‹¤'}\")\n",
    "\n",
    "if feature_importance is not None:\n",
    "    top_3_features = feature_importance.head(3)['feature'].tolist()\n",
    "    print(f\"   - ê°€ì¥ ì¤‘ìš”í•œ Features: {', '.join(top_3_features)}\")\n",
    "\n",
    "print(f\"\\n5. ë‹¤ìŒ ë‹¨ê³„\")\n",
    "print(f\"   - Feature Engineering ì¶”ê°€ (ì´ë²¤íŠ¸/ë‰´ìŠ¤ ë°ì´í„°)\")\n",
    "print(f\"   - ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (ë¶„ë¥˜ + íšŒê·€)\")\n",
    "print(f\"   - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\")\n",
    "print(f\"   - ë°±í…ŒìŠ¤íŒ… ì‹œë®¬ë ˆì´ì…˜\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë‹¤ìŒ ë…¸íŠ¸ë¶\n",
    "\n",
    "- **03_feature_engineering.ipynb**: ì¶”ê°€ Feature ìƒì„± (ì´ë²¤íŠ¸, ë‰´ìŠ¤ ë“±)\n",
    "- **04_modeling_classifier.ipynb**: Model 1 (ë¶„ë¥˜ ëª¨ë¸) í•™ìŠµ\n",
    "- **05_modeling_regressor.ipynb**: Model 2 & 3 (íšŒê·€ ëª¨ë¸) í•™ìŠµ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price-predict-eVNULRoT-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
